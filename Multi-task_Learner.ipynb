{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "import time\n",
    "\n",
    "import load_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fc_layer(input, size_in, size_out, name=\"fully-connected\"):\n",
    "    with tf.name_scope(name):\n",
    "        w = tf.Variable(tf.truncated_normal([size_in, size_out], stddev=0.1))\n",
    "        b = tf.Variable(tf.constant(0.1, shape=[size_out]))\n",
    "        act = tf.matmul(input, w) + b\n",
    "        tf.summary.histogram(\"weights\", w)\n",
    "        tf.summary.histogram(\"biases\", b)\n",
    "        tf.summary.histogram(\"activations\", act)\n",
    "        return act\n",
    "    \n",
    "    \n",
    "def train_model(data, labels=[\"tissue\", \"gender\", \"tumor\"], \n",
    "                learning_rate=1e-3, epochs=1000, pca_var=\"\"):\n",
    "    tf.reset_default_graph()\n",
    "    LOGDIR = \"/tmp/tcga_{0}/\".format(str(datetime.datetime.today().date()))\n",
    "    N_IN = data.train.X.shape[1]\n",
    "    N_OUT = {}\n",
    "    for label_name in labels:\n",
    "        N_OUT[label_name] = data.train.y[label_name].shape[1]\n",
    "    N_HIDDEN = int(np.mean(N_IN + sum(N_OUT.values())))\n",
    "    \n",
    "    x = tf.placeholder(tf.float32, [None, N_IN], name=\"x\")\n",
    "    y_true, y_pred = {}, {}\n",
    "    xent, accuracy = {}, {}\n",
    "    train_summ, test_summ = {}, {}\n",
    "    for label_name in labels:\n",
    "        y_true[label_name] = tf.placeholder(tf.float32, \n",
    "                                            [None, N_OUT[label_name]], \n",
    "                                            name=label_name)\n",
    "        hidden = tf.nn.relu(fc_layer(x, N_IN, N_HIDDEN, name=\"fc-\"+label_name), name=\"hidden\")\n",
    "        y_pred[label_name] = fc_layer(hidden, N_HIDDEN, N_OUT[label_name], name=\"softmax-\"+label_name)\n",
    "        xent[label_name] = tf.reduce_mean(\n",
    "            tf.nn.softmax_cross_entropy_with_logits(\n",
    "                labels=y_true[label_name], logits=y_pred[label_name]), name=\"xent\")\n",
    "        correct_prediction = tf.equal(tf.argmax(y_pred[label_name], 1), \n",
    "                                      tf.argmax(y_true[label_name], 1))\n",
    "        accuracy[label_name] = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "        with tf.name_scope(label_name):\n",
    "            train_summ[label_name] = tf.summary.scalar(\"train_accuracy_\" + label_name, \n",
    "                                                       accuracy[label_name])\n",
    "            test_summ[label_name] = tf.summary.scalar(\"test_accuracy_\" + label_name, \n",
    "                                                      accuracy[label_name])\n",
    "\n",
    "    train_step = tf.train.AdamOptimizer(learning_rate).minimize(\n",
    "        xent[labels[0]] + xent[labels[1]] + xent[labels[2]])\n",
    "\n",
    "    sess = tf.Session()\n",
    "    summ = tf.summary.merge_all()\n",
    "    writer = tf.summary.FileWriter(LOGDIR + \"pca{0}\".format(pca_var))\n",
    "    writer.add_graph(sess.graph)\n",
    "\n",
    "    # training\n",
    "    t0 = time.time()\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "\n",
    "    epoch_completed = 0\n",
    "    while data.train.epochs_completed <= epochs:\n",
    "        batch_x, batch_y = data.train.next_batch(100)\n",
    "        sess.run(train_step, feed_dict={x: batch_x, \n",
    "                                        y_true[labels[0]]: batch_y[labels[0]],\n",
    "                                        y_true[labels[1]]: batch_y[labels[1]],\n",
    "                                        y_true[labels[2]]: batch_y[labels[2]],\n",
    "                                       })\n",
    "        if data.train.epochs_completed > epoch_completed:\n",
    "            epoch_completed += 1\n",
    "            [train_s, s] = sess.run([train_summ, summ],\n",
    "                feed_dict={x: tcga.train.X, \n",
    "                           y_true[labels[0]]: tcga.train.y[labels[0]],\n",
    "                           y_true[labels[1]]: tcga.train.y[labels[1]],\n",
    "                           y_true[labels[2]]: tcga.train.y[labels[2]],\n",
    "                          })\n",
    "            test_s = sess.run(test_summ,\n",
    "                feed_dict={x: tcga.test.X, \n",
    "                           y_true[labels[0]]: tcga.test.y[labels[0]],\n",
    "                           y_true[labels[1]]: tcga.test.y[labels[1]],\n",
    "                           y_true[labels[2]]: tcga.test.y[labels[2]],\n",
    "                          })\n",
    "            for label_name in labels:\n",
    "                writer.add_summary(train_s[label_name], epoch_completed)\n",
    "                writer.add_summary(test_s[label_name], epoch_completed)\n",
    "            writer.add_summary(s, epoch_completed)\n",
    "            if epoch_completed % 10 == 0:\n",
    "                print(\"epoch completed\", epoch_completed)                \n",
    "    print(\"training time:\", time.time() - t0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9\n",
      "epoch completed 10\n",
      "epoch completed 20\n",
      "epoch completed 30\n",
      "epoch completed 40\n",
      "epoch completed 50\n",
      "epoch completed 60\n",
      "epoch completed 70\n",
      "epoch completed 80\n",
      "epoch completed 90\n",
      "epoch completed 100\n",
      "epoch completed 110\n",
      "epoch completed 120\n",
      "epoch completed 130\n",
      "epoch completed 140\n",
      "epoch completed 150\n",
      "epoch completed 160\n",
      "epoch completed 170\n",
      "epoch completed 180\n",
      "epoch completed 190\n",
      "epoch completed 200\n",
      "epoch completed 210\n",
      "epoch completed 220\n",
      "epoch completed 230\n",
      "epoch completed 240\n",
      "epoch completed 250\n",
      "epoch completed 260\n",
      "epoch completed 270\n",
      "epoch completed 280\n",
      "epoch completed 290\n",
      "epoch completed 300\n",
      "epoch completed 310\n",
      "epoch completed 320\n",
      "epoch completed 330\n",
      "epoch completed 340\n",
      "epoch completed 350\n",
      "epoch completed 360\n",
      "epoch completed 370\n",
      "epoch completed 380\n",
      "epoch completed 390\n",
      "epoch completed 400\n",
      "epoch completed 410\n",
      "epoch completed 420\n",
      "epoch completed 430\n",
      "epoch completed 440\n",
      "epoch completed 450\n",
      "epoch completed 460\n",
      "epoch completed 470\n",
      "epoch completed 480\n",
      "epoch completed 490\n",
      "epoch completed 500\n",
      "epoch completed 510\n",
      "epoch completed 520\n",
      "epoch completed 530\n",
      "epoch completed 540\n",
      "epoch completed 550\n",
      "epoch completed 560\n",
      "epoch completed 570\n",
      "epoch completed 580\n",
      "epoch completed 590\n",
      "epoch completed 600\n",
      "epoch completed 610\n",
      "epoch completed 620\n",
      "epoch completed 630\n",
      "epoch completed 640\n",
      "epoch completed 650\n",
      "epoch completed 660\n",
      "epoch completed 670\n",
      "epoch completed 680\n",
      "epoch completed 690\n",
      "epoch completed 700\n",
      "epoch completed 710\n",
      "epoch completed 720\n",
      "epoch completed 730\n",
      "epoch completed 740\n",
      "epoch completed 750\n",
      "epoch completed 760\n",
      "epoch completed 770\n",
      "epoch completed 780\n",
      "epoch completed 790\n",
      "epoch completed 800\n",
      "epoch completed 810\n",
      "epoch completed 820\n",
      "epoch completed 830\n",
      "epoch completed 840\n",
      "epoch completed 850\n",
      "epoch completed 860\n",
      "epoch completed 870\n",
      "epoch completed 880\n",
      "epoch completed 890\n",
      "epoch completed 900\n",
      "epoch completed 910\n",
      "epoch completed 920\n",
      "epoch completed 930\n",
      "epoch completed 940\n",
      "epoch completed 950\n",
      "epoch completed 960\n",
      "epoch completed 970\n",
      "epoch completed 980\n",
      "epoch completed 990\n",
      "epoch completed 1000\n",
      "training time: 721.8874845504761\n"
     ]
    }
   ],
   "source": [
    "for PCA_variance in [0.9]:\n",
    "    print(PCA_variance)\n",
    "    tcga = load_data.read_data_sets(\"./data/mRNA_PCA_{0}_variance_MinMaxScaled.csv\".format(PCA_variance))\n",
    "    train_model(tcga, epochs=1000, pca_var=PCA_variance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
