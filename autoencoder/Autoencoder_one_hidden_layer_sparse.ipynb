{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/molly/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import time\n",
    "import datetime\n",
    "from pprint import pprint as pp\n",
    "import sys\n",
    "\n",
    "sys.path.insert(0, '/home/molly/Desktop/DeepTCGA/')\n",
    "import load_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fc_layer(A_prev, size_in, size_out, name=\"fully-connected\"):\n",
    "    with tf.name_scope(name):\n",
    "        w = tf.Variable(tf.truncated_normal([size_in, size_out], mean=0, stddev=0.1))\n",
    "        b = tf.Variable(tf.constant(0.1, shape=[size_out]))\n",
    "        act = tf.matmul(A_prev, w) + b\n",
    "        return act, w, b\n",
    "    \n",
    "\n",
    "def random_sparse_layer(A_prev, size_in, size_out, sparsity, name=\"sparse\"):\n",
    "    if sparsity < 0.01:\n",
    "        mask = generate_really_sparse_mask(size_in, size_out, sparsity)\n",
    "    else:\n",
    "        mask = generate_random_sparse_mask(size_in, size_out, sparsity)\n",
    "    with tf.name_scope(name):\n",
    "        w = tf.Variable(tf.truncated_normal([size_in, size_out], mean=0, stddev=0.1))\n",
    "        w_masked = tf.multiply(mask, w)\n",
    "        b = tf.Variable(tf.constant(0.1, shape=[size_out]))\n",
    "        act = tf.matmul(A_prev, w_masked) + b\n",
    "        return act, w, w_masked, mask, b\n",
    "\n",
    "    \n",
    "def build_model(x, N_IN, N_HIDDEN, sparsity=0.5):\n",
    "    parameters = {}\n",
    "    z1, w1_init, w1_sparse, mask1, b1 = random_sparse_layer(\n",
    "        x, N_IN, N_HIDDEN, sparsity, name=\"sparse1\")\n",
    "    parameters.update({\"z1\":z1, \"w1_init\": w1_init,\"w1_sparse\":w1_sparse, \n",
    "                       \"mask1\": mask1, \"b1\": b1})\n",
    "    hidden = tf.nn.leaky_relu(z1, name=\"hidden\")\n",
    "    x_recon, w2, b2 = fc_layer(hidden, N_HIDDEN, N_IN, name=\"fc1\")\n",
    "    parameters.update({\"w2\": w2, \"b2\": b2})\n",
    "    return x_recon, parameters\n",
    "\n",
    "\n",
    "\n",
    "def build_model_right_sparse(x, N_IN, N_HIDDEN, sparsity=0.5):\n",
    "    parameters = {}\n",
    "    z1, w1, b1 = fc_layer(x, N_IN, N_HIDDEN, name=\"fc1\")\n",
    "    parameters.update({\"w1\": w1, \"b1\": b1})    \n",
    "    hidden = tf.nn.leaky_relu(z1, name=\"hidden\")\n",
    "    x_recon, w2_init, w2_sparse, mask2, b2 = random_sparse_layer(\n",
    "        hidden, N_HIDDEN, N_IN, sparsity, name=\"sparse1\")\n",
    "    parameters.update({\"w2_init\": w2_init, \"w2_sparse\":w2_sparse, \n",
    "                       \"mask2\": mask2, \"b2\": b2})\n",
    "    return x_recon, parameters\n",
    "\n",
    "\n",
    "def build_model_both_sparse_assymetric(x, N_IN, N_HIDDEN, sparsity=0.5):\n",
    "    parameters = {}\n",
    "    z1, w1_init, w1_sparse, mask1, b1 = random_sparse_layer(\n",
    "        x, N_IN, N_HIDDEN, sparsity, name=\"sparse1\")\n",
    "    parameters.update({\"z1\":z1, \"w1_init\": w1_init,\"w1_sparse\":w1_sparse, \n",
    "                       \"mask1\": mask1, \"b1\": b1})\n",
    "    hidden = tf.nn.leaky_relu(z1, name=\"hidden\")\n",
    "    x_recon, w2_init, w2_sparse, mask2, b2 = random_sparse_layer(\n",
    "        hidden, N_HIDDEN, N_IN, sparsity, name=\"sparse2\")\n",
    "    parameters.update({\"w2_init\": w2_init, \"w2_sparse\":w2_sparse, \n",
    "                       \"mask2\": mask2, \"b2\": b2}) \n",
    "    return x_recon, parameters\n",
    "\n",
    "\n",
    "def build_model_both_sparse_symetric(x, N_IN, N_HIDDEN, sparsity=0.5):\n",
    "    parameters = {}\n",
    "    z1, w1_init, w1_sparse, mask1, b1 = random_sparse_layer(\n",
    "        x, N_IN, N_HIDDEN, sparsity, name=\"sparse1\")\n",
    "    parameters.update({\"z1\":z1, \"w1_init\": w1_init,\"w1_sparse\":w1_sparse, \n",
    "                       \"mask1\": mask1, \"b1\": b1})\n",
    "    hidden = tf.nn.leaky_relu(z1, name=\"hidden\")\n",
    "    mask2 =tf.transpose(mask1)\n",
    "    w2_init = tf.Variable(tf.truncated_normal([N_HIDDEN, N_IN], mean=0, stddev=0.1))\n",
    "    w2_sparse = tf.multiply(mask2, w2_init)\n",
    "    b2 = tf.Variable(tf.constant(0.1, shape=[N_IN]))\n",
    "    x_recon = tf.matmul(hidden, w2_sparse) + b2\n",
    "    parameters.update({\"w2_init\": w2_init, \"w2_sparse\":w2_sparse, \n",
    "                       \"mask2\": mask2, \"b2\": b2})     \n",
    "    return x_recon, parameters\n",
    "\n",
    "\n",
    "def back_prop(x, x_recon, learning_rate):\n",
    "    loss = tf.reduce_mean(tf.square(x_recon - x))\n",
    "    train_step = tf.train.AdamOptimizer(learning_rate).minimize(loss)\n",
    "    return train_step\n",
    "\n",
    "\n",
    "def feed_forward(x, parameters):\n",
    "    w1_sparse, b1 = parameters[\"w1_sparse\"], parameters[\"b1\"]\n",
    "    hidden = tf.nn.leaky_relu(tf.matmul(x, w1_sparse) + b1)\n",
    "    w2, b2 = parameters[\"w2\"], parameters[\"b2\"]\n",
    "    x_recon = tf.matmul(hidden, w2) + b2\n",
    "    return x_recon, hidden\n",
    "\n",
    "\n",
    "def feed_forward_right_sparse(x, parameters):\n",
    "    w1, b1 = parameters[\"w1\"], parameters[\"b1\"]\n",
    "    hidden = tf.nn.leaky_relu(tf.matmul(x, w1) + b1)\n",
    "    w2, b2 = parameters[\"w2_sparse\"] ,parameters[\"b2\"]\n",
    "    x_recon = tf.matmul(hidden, w2) + b2\n",
    "    return x_recon, hidden\n",
    "\n",
    "\n",
    "def feed_forward_both_sparse(x, parameters):\n",
    "    w1, b1 = parameters[\"w1_sparse\"], parameters[\"b1\"]\n",
    "    hidden = tf.nn.leaky_relu(tf.matmul(x, w1) + b1)\n",
    "    w2, b2 = parameters[\"w2_sparse\"] ,parameters[\"b2\"]\n",
    "    x_recon = tf.matmul(hidden, w2) + b2\n",
    "    return x_recon, hidden\n",
    "\n",
    "def mse(x, x_recon, name=\"\"):\n",
    "    mse = tf.reduce_mean(tf.square(x_recon-x))\n",
    "    mse_summary = tf.summary.scalar(name + \"_mse\", mse)\n",
    "    return mse, mse_summary\n",
    "\n",
    "\n",
    "def generate_random_sparse_mask(size_in, size_out, sparsity):\n",
    "    \"\"\" make sure each node has at least one edge connecting to it\"\"\"\n",
    "    assert(size_out>=100)\n",
    "    while True:\n",
    "        try:\n",
    "            a = np.random.uniform(low=0, high=1, size=(size_in, size_out))\n",
    "            a = (a>(1-sparsity)).astype(int)\n",
    "            assert((a.sum(axis=1)>1).all())\n",
    "            assert((a.sum(axis=0)>1).all())\n",
    "            break\n",
    "        except AssertionError:\n",
    "            continue\n",
    "    return tf.constant(a.astype('float32'))\n",
    "\n",
    "\n",
    "def generate_really_sparse_mask(size_in, size_out, sparsity):\n",
    "    a = np.random.uniform(low=0, high=1, size=(size_in, size_out))\n",
    "    a = (a>(1-sparsity)).astype(int)\n",
    "    return tf.constant(a.astype('float32'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_model_random(data, batch_size=128, n_hidden=1000, \n",
    "                num_epoch=1000, learning_rate=1e-3, sparsity=1, mode=\"left\", extra=\"\"):\n",
    "    tf.reset_default_graph()\n",
    "    LOGDIR = \"/tmp/tcga_{0}\".format(datetime.datetime.today().date())\n",
    "    N_IN = data.train.num_features\n",
    "    N_OUT = data.train.num_features\n",
    "    N_HIDDEN = n_hidden\n",
    "    \n",
    "    # train step\n",
    "    (train_batch, train_iter, val_all, val_iter, \n",
    "        train_all, train_iter_all) = data.prep_batch(batch_size=batch_size, \n",
    "                                                     count_by=\"epoch\")\n",
    "    x = train_batch[\"X\"]\n",
    "    if mode==\"left\":\n",
    "        x_recon, parameters = build_model(x, N_IN, N_HIDDEN, sparsity=sparsity)\n",
    "    elif mode == \"both\":\n",
    "        x_recon, parameters = build_model_both_sparse_symetric(x, N_IN, N_HIDDEN, sparsity=sparsity)        \n",
    "    else:\n",
    "        raise\n",
    "    train_step = back_prop(x, x_recon, learning_rate)    \n",
    "    \n",
    "    # mse\n",
    "    x_train, x_val = train_all[\"X\"], val_all[\"X\"]\n",
    "    if mode==\"left\":\n",
    "        x_train_recon, train_latent = feed_forward(x_train, parameters)\n",
    "        x_val_recon, val_latent = feed_forward(x_val, parameters)\n",
    "    elif mode == \"both\":\n",
    "        x_train_recon, train_latent = feed_forward_both_sparse(x_train, parameters)\n",
    "        x_val_recon, val_latent = feed_forward_both_sparse(x_val, parameters)\n",
    "    train_mse, train_summ = mse(x_train, x_train_recon, name=\"train\")\n",
    "    val_mse, val_summ = mse(x_val, x_val_recon, name=\"valiation\")\n",
    "    \n",
    "    # run\n",
    "    sess = tf.Session()\n",
    "    summ = tf.summary.merge_all()\n",
    "    writer = tf.summary.FileWriter(LOGDIR + \"ae_{0}\".format(extra))\n",
    "    writer.add_graph(sess.graph)                            \n",
    "    sess.run(tf.global_variables_initializer())\n",
    "\n",
    "    for epoch in range(num_epoch):\n",
    "        sess.run([train_iter.initializer])\n",
    "        t0 = time.time()\n",
    "        try:\n",
    "            while True:\n",
    "                sess.run(train_step)\n",
    "        except tf.errors.OutOfRangeError:\n",
    "            sess.run([train_iter_all.initializer, val_iter.initializer])\n",
    "            [train_error, train_s, val_error, val_s] = sess.run(\n",
    "                [train_mse, train_summ, val_mse, val_summ])\n",
    "            writer.add_summary(train_s, epoch)\n",
    "            writer.add_summary(val_s, epoch)\n",
    "            if epoch % 10 == 0:\n",
    "                print(\"epoch\", epoch)\n",
    "                print(\"training mse:\", train_error, \"validation mse\", val_error)\n",
    "                print(\"epoch time:\", time.time()-t0)\n",
    "#     train_latent = sess.run(train_latent)\n",
    "#     val_latent = sess.run(val_latent)\n",
    "#     np.save(\"./results/AE/train_latent_sparse2.npy\", train_latent)\n",
    "#     np.save(\"./results/AE/val_latent_sparse2.npy\", val_latent)    \n",
    "    sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tcga_pathway = load_data.read_data_sets(\n",
    "    \"../data/TF_network/mRNA_lognorm_StandardScaled_pathway_genes.hdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0\n",
      "training mse: 0.5927379 validation mse 0.604196\n",
      "epoch time: 5.288846015930176\n",
      "epoch 10\n",
      "training mse: 0.20086 validation mse 0.22592442\n",
      "epoch time: 2.948474407196045\n",
      "epoch 20\n",
      "training mse: 0.15078259 validation mse 0.18808544\n",
      "epoch time: 2.9601621627807617\n",
      "epoch 30\n",
      "training mse: 0.12178384 validation mse 0.17031631\n",
      "epoch time: 3.0083060264587402\n",
      "epoch 40\n",
      "training mse: 0.10132204 validation mse 0.15952392\n",
      "epoch time: 2.992415428161621\n",
      "epoch 50\n",
      "training mse: 0.08616658 validation mse 0.15242074\n",
      "epoch time: 2.995379686355591\n",
      "epoch 60\n",
      "training mse: 0.074940056 validation mse 0.1475617\n",
      "epoch time: 2.9606404304504395\n",
      "epoch 70\n",
      "training mse: 0.06617726 validation mse 0.14376137\n",
      "epoch time: 2.972929000854492\n",
      "epoch 80\n",
      "training mse: 0.059859656 validation mse 0.1413004\n",
      "epoch time: 2.9888193607330322\n",
      "epoch 90\n",
      "training mse: 0.05460671 validation mse 0.13909756\n",
      "epoch time: 2.9606916904449463\n",
      "epoch 100\n",
      "training mse: 0.05036956 validation mse 0.13727604\n",
      "epoch time: 2.9577324390411377\n",
      "epoch 110\n",
      "training mse: 0.04700074 validation mse 0.13601437\n",
      "epoch time: 2.9845495223999023\n",
      "epoch 120\n",
      "training mse: 0.044338543 validation mse 0.13506277\n",
      "epoch time: 2.9981000423431396\n",
      "epoch 130\n",
      "training mse: 0.041991 validation mse 0.13428326\n",
      "epoch time: 2.9538607597351074\n",
      "epoch 140\n",
      "training mse: 0.040322307 validation mse 0.1340406\n",
      "epoch time: 2.9894206523895264\n",
      "epoch 150\n",
      "training mse: 0.038747944 validation mse 0.13382928\n",
      "epoch time: 2.9518139362335205\n",
      "epoch 160\n",
      "training mse: 0.03720775 validation mse 0.13345304\n",
      "epoch time: 2.9646925926208496\n",
      "epoch 170\n",
      "training mse: 0.035974894 validation mse 0.13338412\n",
      "epoch time: 2.9795916080474854\n",
      "epoch 180\n",
      "training mse: 0.03496133 validation mse 0.13335878\n",
      "epoch time: 2.984015703201294\n",
      "epoch 190\n",
      "training mse: 0.033960737 validation mse 0.13339333\n",
      "epoch time: 2.97123646736145\n",
      "epoch 200\n",
      "training mse: 0.033245675 validation mse 0.13365214\n",
      "epoch time: 2.982766628265381\n",
      "epoch 210\n",
      "training mse: 0.032451633 validation mse 0.13375719\n",
      "epoch time: 2.950305223464966\n",
      "epoch 220\n",
      "training mse: 0.031879675 validation mse 0.13402541\n",
      "epoch time: 2.9800949096679688\n",
      "epoch 230\n",
      "training mse: 0.03119986 validation mse 0.13412988\n",
      "epoch time: 2.977555513381958\n",
      "epoch 240\n",
      "training mse: 0.030551879 validation mse 0.13431038\n",
      "epoch time: 3.005520820617676\n",
      "epoch 250\n",
      "training mse: 0.030140275 validation mse 0.1346697\n",
      "epoch time: 2.978135824203491\n",
      "epoch 260\n",
      "training mse: 0.02967289 validation mse 0.1349043\n",
      "epoch time: 2.9825491905212402\n",
      "epoch 270\n",
      "training mse: 0.02922153 validation mse 0.13515821\n",
      "epoch time: 2.973093271255493\n",
      "epoch 280\n",
      "training mse: 0.028881809 validation mse 0.13554522\n",
      "epoch time: 2.9744040966033936\n",
      "epoch 290\n",
      "training mse: 0.028370265 validation mse 0.13568585\n",
      "epoch time: 2.963236093521118\n",
      "epoch 300\n",
      "training mse: 0.02809568 validation mse 0.13598911\n",
      "epoch time: 2.9669694900512695\n",
      "epoch 310\n",
      "training mse: 0.027790975 validation mse 0.13637383\n",
      "epoch time: 2.9998772144317627\n",
      "epoch 320\n",
      "training mse: 0.027541721 validation mse 0.13677853\n",
      "epoch time: 2.9698643684387207\n",
      "epoch 330\n",
      "training mse: 0.027237205 validation mse 0.13702606\n",
      "epoch time: 2.9789788722991943\n",
      "epoch 340\n",
      "training mse: 0.02708126 validation mse 0.13751113\n",
      "epoch time: 2.960186004638672\n",
      "epoch 350\n",
      "training mse: 0.026888449 validation mse 0.13779901\n",
      "epoch time: 2.975715398788452\n",
      "epoch 360\n",
      "training mse: 0.02669622 validation mse 0.13805926\n",
      "epoch time: 2.951021671295166\n",
      "epoch 370\n",
      "training mse: 0.026261417 validation mse 0.13820691\n",
      "epoch time: 2.9820446968078613\n",
      "epoch 380\n",
      "training mse: 0.026186142 validation mse 0.13854285\n",
      "epoch time: 2.971000909805298\n",
      "epoch 390\n",
      "training mse: 0.025800418 validation mse 0.13864638\n",
      "epoch time: 2.988626003265381\n",
      "epoch 400\n",
      "training mse: 0.025831053 validation mse 0.13922155\n",
      "epoch time: 2.9928531646728516\n",
      "epoch 410\n",
      "training mse: 0.025655648 validation mse 0.13950574\n",
      "epoch time: 2.9670913219451904\n",
      "epoch 420\n",
      "training mse: 0.025607536 validation mse 0.13987675\n",
      "epoch time: 2.997215986251831\n",
      "epoch 430\n",
      "training mse: 0.025215656 validation mse 0.13992907\n",
      "epoch time: 2.961341619491577\n",
      "epoch 440\n",
      "training mse: 0.025193082 validation mse 0.14029346\n",
      "epoch time: 2.9663093090057373\n",
      "epoch 450\n",
      "training mse: 0.025046343 validation mse 0.14060041\n",
      "epoch time: 2.94871187210083\n",
      "epoch 460\n",
      "training mse: 0.024843523 validation mse 0.14075539\n",
      "epoch time: 3.000204563140869\n",
      "epoch 470\n",
      "training mse: 0.024837533 validation mse 0.1411266\n",
      "epoch time: 2.9892592430114746\n",
      "epoch 480\n",
      "training mse: 0.024611775 validation mse 0.14124653\n",
      "epoch time: 2.976975679397583\n",
      "epoch 490\n",
      "training mse: 0.024488252 validation mse 0.14147186\n",
      "epoch time: 2.9667205810546875\n",
      "epoch 500\n",
      "training mse: 0.024354132 validation mse 0.14172317\n",
      "epoch time: 2.971728801727295\n",
      "epoch 510\n",
      "training mse: 0.024184328 validation mse 0.14187002\n",
      "epoch time: 2.990907907485962\n",
      "epoch 520\n",
      "training mse: 0.024216382 validation mse 0.14227353\n",
      "epoch time: 2.981842279434204\n",
      "epoch 530\n",
      "training mse: 0.024028357 validation mse 0.14240244\n",
      "epoch time: 2.9764323234558105\n",
      "epoch 540\n",
      "training mse: 0.023990499 validation mse 0.14269076\n",
      "epoch time: 2.963120937347412\n",
      "epoch 550\n",
      "training mse: 0.02374959 validation mse 0.14281374\n",
      "epoch time: 2.9567148685455322\n",
      "epoch 560\n",
      "training mse: 0.02366282 validation mse 0.14296019\n",
      "epoch time: 2.9771673679351807\n",
      "epoch 570\n",
      "training mse: 0.023491291 validation mse 0.14317037\n",
      "epoch time: 2.991100311279297\n",
      "epoch 580\n",
      "training mse: 0.02365044 validation mse 0.14359185\n",
      "epoch time: 2.9723174571990967\n",
      "epoch 590\n",
      "training mse: 0.023660265 validation mse 0.14389974\n",
      "epoch time: 2.949657678604126\n",
      "epoch 600\n",
      "training mse: 0.023512816 validation mse 0.14388838\n",
      "epoch time: 2.949265241622925\n",
      "epoch 610\n",
      "training mse: 0.023362475 validation mse 0.14409077\n",
      "epoch time: 2.9606311321258545\n",
      "epoch 620\n",
      "training mse: 0.023142241 validation mse 0.14405504\n",
      "epoch time: 2.9801926612854004\n",
      "epoch 630\n",
      "training mse: 0.023349458 validation mse 0.1445312\n",
      "epoch time: 2.96445894241333\n",
      "epoch 640\n",
      "training mse: 0.022972621 validation mse 0.14441971\n",
      "epoch time: 2.982623815536499\n"
     ]
    }
   ],
   "source": [
    "for sparsity in [0.001]:\n",
    "    for mode in [\"left\", \"both\"]:\n",
    "        train_model_random(tcga_pathway, n_hidden=5500, num_epoch=1000, mode=mode, sparsity=sparsity,\n",
    "            extra=\"5500_hidden_random_sparse_{1}_{0}\".format(mode, sparsity))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def TF_layer(A_prev, name=\"bio-sparse\"):\n",
    "    mask = pd.read_hdf(\"../data/TF_network/TF_gene_matrix_filtered_by_tcga.hdf\", \"mask\")\n",
    "    size_in, size_out = mask.shape\n",
    "    mask = tf.constant(mask.as_matrix().astype(\"float32\"))\n",
    "    with tf.name_scope(name):\n",
    "        w = tf.Variable(tf.truncated_normal([size_in, size_out], mean=0, stddev=0.1))\n",
    "        w_masked = tf.multiply(mask, w)\n",
    "        b = tf.Variable(tf.constant(0.1, shape=[size_out]))\n",
    "        act = tf.matmul(A_prev, w_masked) + b\n",
    "        return act, w, w_masked, mask, b \n",
    "        \n",
    "\n",
    "def build_model_TF_network(x, mode=\"left\"):\n",
    "    parameters = {}\n",
    "    z1, w1_init, w1_sparse, mask1, b1 = TF_layer(x, name=\"bio-sparse\")\n",
    "    parameters.update({\"z1\":z1, \"w1_init\": w1_init,\"w1_sparse\":w1_sparse, \n",
    "                       \"mask1\": mask1, \"b1\": b1})\n",
    "    hidden = tf.nn.leaky_relu(z1, name=\"hidden\")\n",
    "    \n",
    "    if mode==\"left\":\n",
    "        size_out, size_in = int(mask1.shape[0]), int(mask1.shape[1])\n",
    "        x_recon, w2, b2 = fc_layer(hidden, size_in, size_out, name=\"fc1\")\n",
    "        parameters.update({\"w2\": w2, \"b2\": b2})\n",
    "    elif mode == \"both\":\n",
    "        mask2 =tf.transpose(mask1)\n",
    "        size_in, size_out = int(mask2.shape[0]), int(mask2.shape[1])\n",
    "        w2_init = tf.Variable(tf.truncated_normal([size_in, size_out], mean=0, stddev=0.1))\n",
    "        w2_sparse = tf.multiply(mask2, w2_init)\n",
    "        b2 = tf.Variable(tf.constant(0.1, shape=[size_out]))\n",
    "        x_recon = tf.matmul(hidden, w2_sparse) + b2\n",
    "        parameters.update({\"w2_init\": w2_init, \"w2_sparse\":w2_sparse, \n",
    "            \"mask2\": mask2, \"b2\": b2})     \n",
    "    else:\n",
    "        raise\n",
    "    return x_recon, parameters\n",
    "\n",
    "\n",
    "def feed_forward_TF_network(x, parameters, mode=\"left\"):\n",
    "    w1_sparse, b1 = parameters[\"w1_sparse\"], parameters[\"b1\"]\n",
    "    hidden = tf.nn.leaky_relu(tf.matmul(x, w1_sparse) + b1)\n",
    "    if mode == \"left\":\n",
    "        w2, b2 = parameters[\"w2\"], parameters[\"b2\"]\n",
    "    elif mode == \"both\":\n",
    "        w2, b2 = parameters[\"w2_sparse\"] ,parameters[\"b2\"]\n",
    "    else:\n",
    "        raise\n",
    "    x_recon = tf.matmul(hidden, w2) + b2\n",
    "    return x_recon, hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_model_TF_network(data, batch_size=128, num_epoch=1000, \n",
    "                           learning_rate=1e-3, mode=\"left\", extra=\"\"):\n",
    "    tf.reset_default_graph()\n",
    "    LOGDIR = \"/tmp/tcga_{0}\".format(datetime.datetime.today().date())\n",
    "    \n",
    "    # train step\n",
    "    (train_batch, train_iter, val_all, val_iter, \n",
    "        train_all, train_iter_all) = data.prep_batch(batch_size=batch_size, \n",
    "                                                     count_by=\"epoch\")\n",
    "    x = train_batch[\"X\"]\n",
    "    x_recon, parameters = build_model_TF_network(x, mode=mode)\n",
    "    train_step = back_prop(x, x_recon, learning_rate)    \n",
    "    \n",
    "    # mse\n",
    "    x_train, x_val = train_all[\"X\"], val_all[\"X\"]\n",
    "    x_train_recon, train_latent = feed_forward_TF_network(x_train, parameters, mode=mode)\n",
    "    x_val_recon, val_latent = feed_forward_TF_network(x_val, parameters, mode=mode)\n",
    "    train_mse, train_summ = mse(x_train, x_train_recon, name=\"train\")\n",
    "    val_mse, val_summ = mse(x_val, x_val_recon, name=\"valiation\")\n",
    "    \n",
    "    # run\n",
    "    sess = tf.Session()\n",
    "    summ = tf.summary.merge_all()\n",
    "    writer = tf.summary.FileWriter(LOGDIR + \"ae_{0}\".format(extra))\n",
    "    writer.add_graph(sess.graph)                            \n",
    "    sess.run(tf.global_variables_initializer())\n",
    "\n",
    "    for epoch in range(num_epoch):\n",
    "        sess.run([train_iter.initializer])\n",
    "        t0 = time.time()\n",
    "        try:\n",
    "            while True:\n",
    "                sess.run(train_step)\n",
    "        except tf.errors.OutOfRangeError:\n",
    "            sess.run([train_iter_all.initializer, val_iter.initializer])\n",
    "            [train_error, train_s, val_error, val_s] = sess.run(\n",
    "                [train_mse, train_summ, val_mse, val_summ])\n",
    "            writer.add_summary(train_s, epoch)\n",
    "            writer.add_summary(val_s, epoch)\n",
    "            if epoch % 10 == 0:\n",
    "                print(\"epoch\", epoch)\n",
    "                print(\"training mse:\", train_error, \"validation mse\", val_error)\n",
    "                print(\"epoch time:\", time.time()-t0)  \n",
    "    sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "tcga_pathway = load_data.read_data_sets(\n",
    "    \"../data/TF_network/mRNA_lognorm_StandardScaled_pathway_genes.hdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0\n",
      "training mse: 0.93593585 validation mse 0.9264781\n",
      "epoch time: 11.377406358718872\n",
      "epoch 10\n",
      "training mse: 0.4717485 validation mse 0.4673784\n",
      "epoch time: 3.204188823699951\n",
      "epoch 20\n",
      "training mse: 0.41342133 validation mse 0.40974596\n",
      "epoch time: 3.2118191719055176\n",
      "epoch 30\n",
      "training mse: 0.39847544 validation mse 0.39497766\n",
      "epoch time: 3.191128730773926\n",
      "epoch 40\n",
      "training mse: 0.3896634 validation mse 0.38624182\n",
      "epoch time: 3.209786891937256\n",
      "epoch 50\n",
      "training mse: 0.38418385 validation mse 0.3807922\n",
      "epoch time: 3.2109735012054443\n",
      "epoch 60\n",
      "training mse: 0.3805112 validation mse 0.37713966\n",
      "epoch time: 3.213521718978882\n",
      "epoch 70\n",
      "training mse: 0.3779678 validation mse 0.374563\n",
      "epoch time: 3.2344577312469482\n",
      "epoch 80\n",
      "training mse: 0.37617072 validation mse 0.37273845\n",
      "epoch time: 3.227200984954834\n",
      "epoch 90\n",
      "training mse: 0.37500533 validation mse 0.37157983\n",
      "epoch time: 3.2343859672546387\n",
      "epoch 100\n",
      "training mse: 0.37405384 validation mse 0.37064955\n",
      "epoch time: 3.200198173522949\n",
      "epoch 110\n",
      "training mse: 0.37336877 validation mse 0.3700112\n",
      "epoch time: 3.209186315536499\n",
      "epoch 120\n",
      "training mse: 0.37277183 validation mse 0.3693687\n",
      "epoch time: 3.227874994277954\n",
      "epoch 130\n",
      "training mse: 0.37233117 validation mse 0.36891517\n",
      "epoch time: 3.2215945720672607\n",
      "epoch 140\n",
      "training mse: 0.3719303 validation mse 0.3685077\n",
      "epoch time: 3.2073512077331543\n",
      "epoch 150\n",
      "training mse: 0.3716539 validation mse 0.36826134\n",
      "epoch time: 3.2184009552001953\n",
      "epoch 160\n",
      "training mse: 0.3713392 validation mse 0.36793885\n",
      "epoch time: 3.230851650238037\n",
      "epoch 170\n",
      "training mse: 0.37111092 validation mse 0.36771122\n",
      "epoch time: 3.230997323989868\n",
      "epoch 180\n",
      "training mse: 0.37090856 validation mse 0.36749125\n",
      "epoch time: 3.2189669609069824\n",
      "epoch 190\n",
      "training mse: 0.3706818 validation mse 0.36726314\n",
      "epoch time: 3.2321226596832275\n",
      "epoch 200\n",
      "training mse: 0.370581 validation mse 0.3671684\n",
      "epoch time: 3.233994245529175\n",
      "epoch 210\n",
      "training mse: 0.37039468 validation mse 0.36695433\n",
      "epoch time: 3.2000792026519775\n",
      "epoch 220\n",
      "training mse: 0.37027752 validation mse 0.36683306\n",
      "epoch time: 3.2000045776367188\n",
      "epoch 230\n",
      "training mse: 0.37019634 validation mse 0.36676785\n",
      "epoch time: 3.2297728061676025\n",
      "epoch 240\n",
      "training mse: 0.370082 validation mse 0.36667112\n",
      "epoch time: 3.2253620624542236\n",
      "epoch 250\n",
      "training mse: 0.36997044 validation mse 0.366521\n",
      "epoch time: 3.224966526031494\n",
      "epoch 260\n",
      "training mse: 0.36992523 validation mse 0.36647645\n",
      "epoch time: 3.2176005840301514\n",
      "epoch 270\n",
      "training mse: 0.36980858 validation mse 0.3663492\n",
      "epoch time: 3.226677656173706\n",
      "epoch 280\n",
      "training mse: 0.36969543 validation mse 0.36625007\n",
      "epoch time: 3.2296395301818848\n",
      "epoch 290\n",
      "training mse: 0.36969116 validation mse 0.36624205\n",
      "epoch time: 3.2383368015289307\n",
      "epoch 300\n",
      "training mse: 0.36961833 validation mse 0.36617392\n",
      "epoch time: 3.1967194080352783\n",
      "epoch 310\n",
      "training mse: 0.3695576 validation mse 0.36613908\n",
      "epoch time: 3.240663766860962\n",
      "epoch 320\n",
      "training mse: 0.36952615 validation mse 0.36611015\n",
      "epoch time: 3.2394537925720215\n",
      "epoch 330\n",
      "training mse: 0.36946893 validation mse 0.36604407\n",
      "epoch time: 3.2538180351257324\n",
      "epoch 340\n",
      "training mse: 0.36940035 validation mse 0.36594886\n",
      "epoch time: 3.212946653366089\n",
      "epoch 350\n",
      "training mse: 0.36938798 validation mse 0.36596587\n",
      "epoch time: 3.206554651260376\n",
      "epoch 360\n",
      "training mse: 0.36932975 validation mse 0.36588764\n",
      "epoch time: 3.2140133380889893\n",
      "epoch 370\n",
      "training mse: 0.3692998 validation mse 0.3658768\n",
      "epoch time: 3.2039685249328613\n",
      "epoch 380\n",
      "training mse: 0.36925435 validation mse 0.36582252\n",
      "epoch time: 3.212886333465576\n",
      "epoch 390\n",
      "training mse: 0.3692413 validation mse 0.3658766\n",
      "epoch time: 3.2311971187591553\n",
      "epoch 400\n",
      "training mse: 0.36918408 validation mse 0.36577493\n",
      "epoch time: 3.221498966217041\n",
      "epoch 410\n",
      "training mse: 0.3691759 validation mse 0.3657395\n",
      "epoch time: 3.22438907623291\n",
      "epoch 420\n",
      "training mse: 0.36913422 validation mse 0.36573207\n",
      "epoch time: 3.217083215713501\n",
      "epoch 430\n",
      "training mse: 0.36912552 validation mse 0.36573744\n",
      "epoch time: 3.2506062984466553\n",
      "epoch 440\n",
      "training mse: 0.3690892 validation mse 0.36570406\n",
      "epoch time: 3.210253953933716\n",
      "epoch 450\n",
      "training mse: 0.3690787 validation mse 0.36569488\n",
      "epoch time: 3.246049404144287\n",
      "epoch 460\n",
      "training mse: 0.36903614 validation mse 0.36563712\n",
      "epoch time: 3.2191078662872314\n",
      "epoch 470\n",
      "training mse: 0.36902338 validation mse 0.3656355\n",
      "epoch time: 3.2478692531585693\n",
      "epoch 480\n",
      "training mse: 0.36905056 validation mse 0.36566678\n",
      "epoch time: 3.2163589000701904\n",
      "epoch 490\n",
      "training mse: 0.36898512 validation mse 0.365597\n",
      "epoch time: 3.2175447940826416\n",
      "epoch 500\n",
      "training mse: 0.3689546 validation mse 0.36553922\n",
      "epoch time: 3.212524652481079\n",
      "epoch 510\n",
      "training mse: 0.3689062 validation mse 0.36552152\n",
      "epoch time: 3.221208095550537\n",
      "epoch 520\n",
      "training mse: 0.36890692 validation mse 0.36552155\n",
      "epoch time: 3.233193874359131\n",
      "epoch 530\n",
      "training mse: 0.36892274 validation mse 0.36558023\n",
      "epoch time: 3.2183785438537598\n",
      "epoch 540\n",
      "training mse: 0.36885628 validation mse 0.36547834\n",
      "epoch time: 3.223658323287964\n",
      "epoch 550\n",
      "training mse: 0.3688773 validation mse 0.36545452\n",
      "epoch time: 3.222689628601074\n",
      "epoch 560\n",
      "training mse: 0.3688478 validation mse 0.36545822\n",
      "epoch time: 3.238313913345337\n",
      "epoch 570\n",
      "training mse: 0.36885133 validation mse 0.36544043\n",
      "epoch time: 3.227938413619995\n",
      "epoch 580\n",
      "training mse: 0.3687965 validation mse 0.36542428\n",
      "epoch time: 3.2441396713256836\n",
      "epoch 590\n",
      "training mse: 0.36881286 validation mse 0.36543643\n",
      "epoch time: 3.242223024368286\n",
      "epoch 600\n",
      "training mse: 0.368808 validation mse 0.36544916\n",
      "epoch time: 3.232222080230713\n",
      "epoch 610\n",
      "training mse: 0.3687675 validation mse 0.36540318\n",
      "epoch time: 3.2279462814331055\n",
      "epoch 620\n",
      "training mse: 0.3687735 validation mse 0.36541653\n",
      "epoch time: 3.266965389251709\n",
      "epoch 630\n",
      "training mse: 0.368757 validation mse 0.36545452\n",
      "epoch time: 3.2228338718414307\n",
      "epoch 640\n",
      "training mse: 0.3686707 validation mse 0.36531422\n",
      "epoch time: 3.1964962482452393\n",
      "epoch 650\n",
      "training mse: 0.36869115 validation mse 0.36531132\n",
      "epoch time: 3.198455810546875\n",
      "epoch 660\n",
      "training mse: 0.36867908 validation mse 0.36531806\n",
      "epoch time: 3.2202095985412598\n",
      "epoch 670\n",
      "training mse: 0.36864808 validation mse 0.36530188\n",
      "epoch time: 3.213937520980835\n",
      "epoch 680\n",
      "training mse: 0.3686453 validation mse 0.36525893\n",
      "epoch time: 3.2312917709350586\n",
      "epoch 690\n",
      "training mse: 0.36863652 validation mse 0.36525112\n",
      "epoch time: 3.228386640548706\n",
      "epoch 700\n",
      "training mse: 0.36862954 validation mse 0.36527315\n",
      "epoch time: 3.219803810119629\n",
      "epoch 710\n",
      "training mse: 0.36860517 validation mse 0.36525288\n",
      "epoch time: 3.2314438819885254\n",
      "epoch 720\n",
      "training mse: 0.36856925 validation mse 0.36520737\n",
      "epoch time: 3.239997625350952\n",
      "epoch 730\n",
      "training mse: 0.36858308 validation mse 0.36520448\n",
      "epoch time: 3.2096188068389893\n",
      "epoch 740\n",
      "training mse: 0.36857486 validation mse 0.36521593\n",
      "epoch time: 3.235685348510742\n",
      "epoch 750\n",
      "training mse: 0.36857086 validation mse 0.36524117\n",
      "epoch time: 3.221393346786499\n",
      "epoch 760\n",
      "training mse: 0.36853656 validation mse 0.36520088\n",
      "epoch time: 3.2226622104644775\n",
      "epoch 770\n",
      "training mse: 0.36855242 validation mse 0.36518\n",
      "epoch time: 3.2189488410949707\n",
      "epoch 780\n",
      "training mse: 0.3685401 validation mse 0.36514306\n",
      "epoch time: 3.2125298976898193\n",
      "epoch 790\n",
      "training mse: 0.3685189 validation mse 0.36513326\n",
      "epoch time: 3.238299608230591\n",
      "epoch 800\n",
      "training mse: 0.36849776 validation mse 0.3651446\n",
      "epoch time: 3.216486930847168\n",
      "epoch 810\n",
      "training mse: 0.36851913 validation mse 0.36515066\n",
      "epoch time: 3.240892171859741\n",
      "epoch 820\n",
      "training mse: 0.36852244 validation mse 0.36518258\n",
      "epoch time: 3.215114116668701\n",
      "epoch 830\n",
      "training mse: 0.36847323 validation mse 0.36513132\n",
      "epoch time: 3.2233850955963135\n",
      "epoch 840\n",
      "training mse: 0.3684747 validation mse 0.36510378\n",
      "epoch time: 3.2012522220611572\n",
      "epoch 850\n",
      "training mse: 0.36848217 validation mse 0.36516076\n",
      "epoch time: 3.225618362426758\n",
      "epoch 860\n",
      "training mse: 0.36843237 validation mse 0.3650869\n",
      "epoch time: 3.2299752235412598\n",
      "epoch 870\n",
      "training mse: 0.368448 validation mse 0.36506632\n",
      "epoch time: 3.2391037940979004\n",
      "epoch 880\n",
      "training mse: 0.36844686 validation mse 0.36507773\n",
      "epoch time: 3.1984074115753174\n",
      "epoch 890\n",
      "training mse: 0.36845207 validation mse 0.36511678\n",
      "epoch time: 3.2223944664001465\n",
      "epoch 900\n",
      "training mse: 0.36842495 validation mse 0.3650752\n",
      "epoch time: 3.2207632064819336\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 910\n",
      "training mse: 0.36841357 validation mse 0.36502257\n",
      "epoch time: 3.218006134033203\n",
      "epoch 920\n",
      "training mse: 0.3683674 validation mse 0.3649963\n",
      "epoch time: 3.2376067638397217\n",
      "epoch 930\n",
      "training mse: 0.36840606 validation mse 0.36504743\n",
      "epoch time: 3.233531951904297\n",
      "epoch 940\n",
      "training mse: 0.36835873 validation mse 0.36502698\n",
      "epoch time: 3.211911201477051\n",
      "epoch 950\n",
      "training mse: 0.36838007 validation mse 0.3650395\n",
      "epoch time: 3.2057337760925293\n",
      "epoch 960\n",
      "training mse: 0.36835527 validation mse 0.36500624\n",
      "epoch time: 3.228374719619751\n",
      "epoch 970\n",
      "training mse: 0.36837825 validation mse 0.3649882\n",
      "epoch time: 3.2440805435180664\n",
      "epoch 980\n",
      "training mse: 0.36835417 validation mse 0.364966\n",
      "epoch time: 3.2063512802124023\n",
      "epoch 990\n",
      "training mse: 0.3683502 validation mse 0.36500385\n",
      "epoch time: 3.2377266883850098\n"
     ]
    }
   ],
   "source": [
    "for mode in [\"both\"]:\n",
    "    train_model_TF_network(tcga_pathway, num_epoch=1000, mode=mode, \n",
    "                           extra=\"TF_network_sparse_{0}\".format(mode))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
