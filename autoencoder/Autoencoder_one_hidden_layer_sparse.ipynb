{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import time\n",
    "import datetime\n",
    "from pprint import pprint as pp\n",
    "import sys\n",
    "\n",
    "sys.path.insert(0, '/home/molly/Desktop/DeepTCGA/')\n",
    "import load_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fc_layer(A_prev, size_in, size_out, name=\"fully-connected\"):\n",
    "    with tf.name_scope(name):\n",
    "        w = tf.Variable(tf.truncated_normal([size_in, size_out], mean=0, stddev=0.1))\n",
    "        b = tf.Variable(tf.constant(0.1, shape=[size_out]))\n",
    "        act = tf.matmul(A_prev, w) + b\n",
    "        return act, w, b\n",
    "    \n",
    "\n",
    "def random_sparse_layer(A_prev, size_in, size_out, sparsity, name=\"sparse\"):\n",
    "    if sparsity < 0.01:\n",
    "        mask = generate_really_sparse_mask(size_in, size_out, sparsity)\n",
    "    else:\n",
    "        mask = generate_random_sparse_mask(size_in, size_out, sparsity)\n",
    "    with tf.name_scope(name):\n",
    "        w = tf.Variable(tf.truncated_normal([size_in, size_out], mean=0, stddev=0.1))\n",
    "        w_masked = tf.multiply(mask, w)\n",
    "        b = tf.Variable(tf.constant(0.1, shape=[size_out]))\n",
    "        act = tf.matmul(A_prev, w_masked) + b\n",
    "        return act, w, w_masked, mask, b\n",
    "\n",
    "    \n",
    "def TF_layer(A_prev, name=\"bio-sparse\"):\n",
    "    mask = pd.read_hdf(\"../data/TF_network/TF_gene_matrix_filtered_by_tcga.hdf\", \"mask\")\n",
    "    size_in, size_out = mask.shape\n",
    "    mask = tf.constant(mask.as_matrix().astype(\"float32\"))\n",
    "    with tf.name_scope(name):\n",
    "        w = tf.Variable(tf.truncated_normal([size_in, size_out], mean=0, stddev=0.1))\n",
    "        w_masked = tf.multiply(mask, w)\n",
    "        b = tf.Variable(tf.constant(0.1, shape=[size_out]))\n",
    "        act = tf.matmul(A_prev, w_masked) + b\n",
    "        return act, w, w_masked, mask, b\n",
    "      \n",
    "        \n",
    "def build_model(x, N_IN, N_HIDDEN, sparsity=0.5):\n",
    "    parameters = {}\n",
    "    z1, w1_init, w1_sparse, mask1, b1 = random_sparse_layer(\n",
    "        x, N_IN, N_HIDDEN, sparsity, name=\"sparse1\")\n",
    "    parameters.update({\"z1\":z1, \"w1_init\": w1_init,\"w1_sparse\":w1_sparse, \n",
    "                       \"mask1\": mask1, \"b1\": b1})\n",
    "    hidden = tf.nn.leaky_relu(z1, name=\"hidden\")\n",
    "    x_recon, w2, b2 = fc_layer(hidden, N_HIDDEN, N_IN, name=\"fc1\")\n",
    "    parameters.update({\"w2\": w2, \"b2\": b2})\n",
    "    return x_recon, parameters\n",
    "\n",
    "\n",
    "def build_model_TF_network(x, mode=\"left\"):\n",
    "    parameters = {}\n",
    "    z1, w1_init, w1_sparse, mask1, b1 = TF_layer(x, name=\"bio-sparse\")\n",
    "    parameters.update({\"z1\":z1, \"w1_init\": w1_init,\"w1_sparse\":w1_sparse, \n",
    "                       \"mask1\": mask1, \"b1\": b1})\n",
    "    hidden = tf.nn.leaky_relu(z1, name=\"hidden\")\n",
    "    \n",
    "    if mode==\"left\":\n",
    "        size_out, size_in = int(mask1.shape[0]), int(mask1.shape[1])\n",
    "        x_recon, w2, b2 = fc_layer(hidden, size_in, size_out, name=\"fc1\")\n",
    "        parameters.update({\"w2\": w2, \"b2\": b2})\n",
    "    elif mode == \"both\":\n",
    "        mask2 =tf.transpose(mask1)\n",
    "        size_in, size_out = mask2.shape\n",
    "        w2_init = tf.Variable(tf.truncated_normal([size_in, size_out], mean=0, stddev=0.1))\n",
    "        w2_sparse = tf.multiply(mask2, w2_init)\n",
    "        b2 = tf.Variable(tf.constant(0.1, shape=[size_in]))\n",
    "        x_recon = tf.matmul(hidden, w2_sparse) + b2\n",
    "        parameters.update({\"w2_init\": w2_init, \"w2_sparse\":w2_sparse, \n",
    "            \"mask2\": mask2, \"b2\": b2})     \n",
    "    else:\n",
    "        raise\n",
    "    return x_recon, parameters\n",
    "\n",
    "\n",
    "def feed_forward_TF_network(x, parameters, mode=\"left\"):\n",
    "    w1_sparse, b1 = parameters[\"w1_sparse\"], parameters[\"b1\"]\n",
    "    hidden = tf.nn.leaky_relu(tf.matmul(x, w1_sparse) + b1)\n",
    "    if mode == \"left\":\n",
    "        w2, b2 = parameters[\"w2\"], parameters[\"b2\"]\n",
    "    elif mode == \"both\":\n",
    "        w2, b2 = parameters[\"w2_sparse\"] ,parameters[\"b2\"]\n",
    "    else:\n",
    "        raise\n",
    "    x_recon = tf.matmul(hidden, w2) + b2\n",
    "    return x_recon, hidden\n",
    "\n",
    "\n",
    "def build_model_right_sparse(x, N_IN, N_HIDDEN, sparsity=0.5):\n",
    "    parameters = {}\n",
    "    z1, w1, b1 = fc_layer(x, N_IN, N_HIDDEN, name=\"fc1\")\n",
    "    parameters.update({\"w1\": w1, \"b1\": b1})    \n",
    "    hidden = tf.nn.leaky_relu(z1, name=\"hidden\")\n",
    "    x_recon, w2_init, w2_sparse, mask2, b2 = random_sparse_layer(\n",
    "        hidden, N_HIDDEN, N_IN, sparsity, name=\"sparse1\")\n",
    "    parameters.update({\"w2_init\": w2_init, \"w2_sparse\":w2_sparse, \n",
    "                       \"mask2\": mask2, \"b2\": b2})\n",
    "    return x_recon, parameters\n",
    "\n",
    "\n",
    "def build_model_both_sparse_assymetric(x, N_IN, N_HIDDEN, sparsity=0.5):\n",
    "    parameters = {}\n",
    "    z1, w1_init, w1_sparse, mask1, b1 = random_sparse_layer(\n",
    "        x, N_IN, N_HIDDEN, sparsity, name=\"sparse1\")\n",
    "    parameters.update({\"z1\":z1, \"w1_init\": w1_init,\"w1_sparse\":w1_sparse, \n",
    "                       \"mask1\": mask1, \"b1\": b1})\n",
    "    hidden = tf.nn.leaky_relu(z1, name=\"hidden\")\n",
    "    x_recon, w2_init, w2_sparse, mask2, b2 = random_sparse_layer(\n",
    "        hidden, N_HIDDEN, N_IN, sparsity, name=\"sparse2\")\n",
    "    parameters.update({\"w2_init\": w2_init, \"w2_sparse\":w2_sparse, \n",
    "                       \"mask2\": mask2, \"b2\": b2}) \n",
    "    return x_recon, parameters\n",
    "\n",
    "\n",
    "def build_model_both_sparse_symetric(x, N_IN, N_HIDDEN, sparsity=0.5):\n",
    "    parameters = {}\n",
    "    z1, w1_init, w1_sparse, mask1, b1 = random_sparse_layer(\n",
    "        x, N_IN, N_HIDDEN, sparsity, name=\"sparse1\")\n",
    "    parameters.update({\"z1\":z1, \"w1_init\": w1_init,\"w1_sparse\":w1_sparse, \n",
    "                       \"mask1\": mask1, \"b1\": b1})\n",
    "    hidden = tf.nn.leaky_relu(z1, name=\"hidden\")\n",
    "    mask2 =tf.transpose(mask1)\n",
    "    w2_init = tf.Variable(tf.truncated_normal([N_HIDDEN, N_IN], mean=0, stddev=0.1))\n",
    "    w2_sparse = tf.multiply(mask2, w2_init)\n",
    "    b2 = tf.Variable(tf.constant(0.1, shape=[N_IN]))\n",
    "    x_recon = tf.matmul(hidden, w2_sparse) + b2\n",
    "    parameters.update({\"w2_init\": w2_init, \"w2_sparse\":w2_sparse, \n",
    "                       \"mask2\": mask2, \"b2\": b2})     \n",
    "    return x_recon, parameters\n",
    "\n",
    "\n",
    "def back_prop(x, x_recon, learning_rate):\n",
    "    loss = tf.reduce_mean(tf.square(x_recon - x))\n",
    "    train_step = tf.train.AdamOptimizer(learning_rate).minimize(loss)\n",
    "    return train_step\n",
    "\n",
    "\n",
    "def feed_forward(x, parameters):\n",
    "    w1_sparse, b1 = parameters[\"w1_sparse\"], parameters[\"b1\"]\n",
    "    hidden = tf.nn.leaky_relu(tf.matmul(x, w1_sparse) + b1)\n",
    "    w2, b2 = parameters[\"w2\"], parameters[\"b2\"]\n",
    "    x_recon = tf.matmul(hidden, w2) + b2\n",
    "    return x_recon, hidden\n",
    "\n",
    "\n",
    "def feed_forward_right_sparse(x, parameters):\n",
    "    w1, b1 = parameters[\"w1\"], parameters[\"b1\"]\n",
    "    hidden = tf.nn.leaky_relu(tf.matmul(x, w1) + b1)\n",
    "    w2, b2 = parameters[\"w2_sparse\"] ,parameters[\"b2\"]\n",
    "    x_recon = tf.matmul(hidden, w2) + b2\n",
    "    return x_recon, hidden\n",
    "\n",
    "\n",
    "def feed_forward_both_sparse(x, parameters):\n",
    "    w1, b1 = parameters[\"w1_sparse\"], parameters[\"b1\"]\n",
    "    hidden = tf.nn.leaky_relu(tf.matmul(x, w1) + b1)\n",
    "    w2, b2 = parameters[\"w2_sparse\"] ,parameters[\"b2\"]\n",
    "    x_recon = tf.matmul(hidden, w2) + b2\n",
    "    return x_recon, hidden\n",
    "\n",
    "def mse(x, x_recon, name=\"\"):\n",
    "    mse = tf.reduce_mean(tf.square(x_recon-x))\n",
    "    mse_summary = tf.summary.scalar(name + \"_mse\", mse)\n",
    "    return mse, mse_summary\n",
    "\n",
    "\n",
    "def generate_random_sparse_mask(size_in, size_out, sparsity):\n",
    "    \"\"\" make sure each node has at least one edge connecting to it\"\"\"\n",
    "    assert(size_out>=100)\n",
    "    while True:\n",
    "        try:\n",
    "            a = np.random.uniform(low=0, high=1, size=(size_in, size_out))\n",
    "            a = (a>(1-sparsity)).astype(int)\n",
    "            assert((a.sum(axis=1)>1).all())\n",
    "            assert((a.sum(axis=0)>1).all())\n",
    "            break\n",
    "        except AssertionError:\n",
    "            continue\n",
    "    return tf.constant(a.astype('float32'))\n",
    "\n",
    "\n",
    "def generate_really_sparse_mask(size_in, size_out, sparsity):\n",
    "    a = np.random.uniform(low=0, high=1, size=(size_in, size_out))\n",
    "    a = (a>(1-sparsity)).astype(int)\n",
    "    return tf.constant(a.astype('float32'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_model_random(data, batch_size=128, n_hidden=1000, \n",
    "                num_epoch=1000, learning_rate=1e-3, sparsity=1, mode=\"left\", extra=\"\"):\n",
    "    tf.reset_default_graph()\n",
    "    LOGDIR = \"/tmp/tcga_{0}\".format(datetime.datetime.today().date())\n",
    "    N_IN = data.train.num_features\n",
    "    N_OUT = data.train.num_features\n",
    "    N_HIDDEN = n_hidden\n",
    "    \n",
    "    # train step\n",
    "    (train_batch, train_iter, val_all, val_iter, \n",
    "        train_all, train_iter_all) = data.prep_batch(batch_size=batch_size, \n",
    "                                                     count_by=\"epoch\")\n",
    "    x = train_batch[\"X\"]\n",
    "    if mode==\"left\":\n",
    "        x_recon, parameters = build_model(x, N_IN, N_HIDDEN, sparsity=sparsity)\n",
    "    elif mode == \"both\":\n",
    "        x_recon, parameters = build_model_both_sparse_symetric(x, N_IN, N_HIDDEN, sparsity=sparsity)        \n",
    "    else:\n",
    "        raise\n",
    "    train_step = back_prop(x, x_recon, learning_rate)    \n",
    "    \n",
    "    # mse\n",
    "    x_train, x_val = train_all[\"X\"], val_all[\"X\"]\n",
    "    if mode==\"left\":\n",
    "        x_train_recon, train_latent = feed_forward(x_train, parameters)\n",
    "        x_val_recon, val_latent = feed_forward(x_val, parameters)\n",
    "    elif mode == \"both\":\n",
    "        x_train_recon, train_latent = feed_forward_both_sparse(x_train, parameters)\n",
    "        x_val_recon, val_latent = feed_forward_both_sparse(x_val, parameters)\n",
    "    train_mse, train_summ = mse(x_train, x_train_recon, name=\"train\")\n",
    "    val_mse, val_summ = mse(x_val, x_val_recon, name=\"valiation\")\n",
    "    \n",
    "    # run\n",
    "    sess = tf.Session()\n",
    "    summ = tf.summary.merge_all()\n",
    "    writer = tf.summary.FileWriter(LOGDIR + \"ae_{0}\".format(extra))\n",
    "    writer.add_graph(sess.graph)                            \n",
    "    sess.run(tf.global_variables_initializer())\n",
    "\n",
    "    for epoch in range(num_epoch):\n",
    "        sess.run([train_iter.initializer])\n",
    "        t0 = time.time()\n",
    "        try:\n",
    "            while True:\n",
    "                sess.run(train_step)\n",
    "        except tf.errors.OutOfRangeError:\n",
    "            sess.run([train_iter_all.initializer, val_iter.initializer])\n",
    "            [train_error, train_s, val_error, val_s] = sess.run(\n",
    "                [train_mse, train_summ, val_mse, val_summ])\n",
    "            writer.add_summary(train_s, epoch)\n",
    "            writer.add_summary(val_s, epoch)\n",
    "            if epoch % 10 == 0:\n",
    "                print(\"epoch\", epoch)\n",
    "                print(\"training mse:\", train_error, \"validation mse\", val_error)\n",
    "                print(\"epoch time:\", time.time()-t0)\n",
    "#     train_latent = sess.run(train_latent)\n",
    "#     val_latent = sess.run(val_latent)\n",
    "#     np.save(\"./results/AE/train_latent_sparse2.npy\", train_latent)\n",
    "#     np.save(\"./results/AE/val_latent_sparse2.npy\", val_latent)    \n",
    "    sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tcga = load_data.read_data_sets(\"../data/mRNA_lognorm_StandardScaled.hdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for sparsity in [0.001]:\n",
    "    for mode in [\"both\"]:\n",
    "        train_model(tcga, n_hidden=5000, num_epoch=1000, mode=mode, sparsity=sparsity,\n",
    "            extra=\"5000_hidden_{0}_sparsity_{1}\".format(mode, sparsity))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_model_TF_network(data, batch_size=128, num_epoch=1000, \n",
    "                           learning_rate=1e-3, mode=\"left\", extra=\"\"):\n",
    "    tf.reset_default_graph()\n",
    "    LOGDIR = \"/tmp/tcga_{0}\".format(datetime.datetime.today().date())\n",
    "    \n",
    "    # train step\n",
    "    (train_batch, train_iter, val_all, val_iter, \n",
    "        train_all, train_iter_all) = data.prep_batch(batch_size=batch_size, \n",
    "                                                     count_by=\"epoch\")\n",
    "    x = train_batch[\"X\"]\n",
    "    x_recon, parameters = build_model_TF_network(x, mode=mode)\n",
    "    train_step = back_prop(x, x_recon, learning_rate)    \n",
    "    \n",
    "    # mse\n",
    "    x_train, x_val = train_all[\"X\"], val_all[\"X\"]\n",
    "    x_train_recon, train_latent = feed_forward_TF_network(x_train, parameters, mode=mode)\n",
    "    x_val_recon, val_latent = feed_forward_TF_network(x_val, parameters, mode=mode)\n",
    "    train_mse, train_summ = mse(x_train, x_train_recon, name=\"train\")\n",
    "    val_mse, val_summ = mse(x_val, x_val_recon, name=\"valiation\")\n",
    "    \n",
    "    # run\n",
    "    sess = tf.Session()\n",
    "    summ = tf.summary.merge_all()\n",
    "    writer = tf.summary.FileWriter(LOGDIR + \"ae_{0}\".format(extra))\n",
    "    writer.add_graph(sess.graph)                            \n",
    "    sess.run(tf.global_variables_initializer())\n",
    "\n",
    "    for epoch in range(num_epoch):\n",
    "        sess.run([train_iter.initializer])\n",
    "        t0 = time.time()\n",
    "        try:\n",
    "            while True:\n",
    "                sess.run(train_step)\n",
    "        except tf.errors.OutOfRangeError:\n",
    "            sess.run([train_iter_all.initializer, val_iter.initializer])\n",
    "            [train_error, train_s, val_error, val_s] = sess.run(\n",
    "                [train_mse, train_summ, val_mse, val_summ])\n",
    "            writer.add_summary(train_s, epoch)\n",
    "            writer.add_summary(val_s, epoch)\n",
    "            if epoch % 10 == 0:\n",
    "                print(\"epoch\", epoch)\n",
    "                print(\"training mse:\", train_error, \"validation mse\", val_error)\n",
    "                print(\"epoch time:\", time.time()-t0)  \n",
    "    sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "tcga_pathway = load_data.read_data_sets(\n",
    "    \"../data/TF_network/mRNA_lognorm_StandardScaled_pathway_genes.hdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0\n",
      "training mse: 0.6419745 validation mse 0.64956063\n",
      "epoch time: 5.3596343994140625\n",
      "epoch 10\n",
      "training mse: 0.21680288 validation mse 0.24029544\n",
      "epoch time: 2.992431879043579\n",
      "epoch 20\n",
      "training mse: 0.16254385 validation mse 0.19722329\n",
      "epoch time: 2.9739174842834473\n",
      "epoch 30\n",
      "training mse: 0.13295195 validation mse 0.178152\n",
      "epoch time: 2.997683048248291\n",
      "epoch 40\n",
      "training mse: 0.112023816 validation mse 0.16684149\n",
      "epoch time: 2.9730398654937744\n"
     ]
    }
   ],
   "source": [
    "for mode in [\"left\", \"both\"]:\n",
    "    train_model_TF_network(tcga_pathway, num_epoch=1000, mode=mode, \n",
    "                           extra=\"TF_network_sparse_{0}\".format(mode))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
