{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/molly/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import time\n",
    "import datetime\n",
    "from pprint import pprint as pp\n",
    "import sys\n",
    "import pickle\n",
    "import glob\n",
    "import os\n",
    "\n",
    "sys.path.insert(0, '/home/molly/Desktop/DeepTCGA/')\n",
    "import load_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fc_layer(A_prev, size_in, size_out, name=\"fully-connected\"):\n",
    "    with tf.name_scope(name):\n",
    "        w = tf.Variable(tf.truncated_normal([size_in, size_out], mean=0, stddev=0.1))\n",
    "        b = tf.Variable(tf.constant(0.1, shape=[size_out]))\n",
    "        act = tf.matmul(A_prev, w) + b\n",
    "        return act, w, b\n",
    "\n",
    "    \n",
    "def build_model(x, N_IN, N_HIDDEN):\n",
    "    parameters = {}\n",
    "    z1, w1, b1 = fc_layer(x, N_IN, N_HIDDEN, name=\"fc1\")\n",
    "    parameters.update({\"w1\": w1, \"b1\": b1})\n",
    "    hidden = tf.nn.leaky_relu(z1, name=\"hidden\")\n",
    "    x_recon, w2, b2 = fc_layer(hidden, N_HIDDEN, N_IN, name=\"fc2\")\n",
    "    parameters.update({\"w2\": w2, \"b2\": b2})\n",
    "    return x_recon, parameters\n",
    "\n",
    "\n",
    "def back_prop(x, x_recon, learning_rate):\n",
    "    loss = tf.reduce_mean(tf.square(x_recon - x))\n",
    "    train_step = tf.train.AdamOptimizer(learning_rate).minimize(loss)\n",
    "    return train_step\n",
    "\n",
    "\n",
    "def feed_forward(x, parameters):\n",
    "    w1, b1 = parameters[\"w1\"], parameters[\"b1\"]\n",
    "    hidden = tf.nn.leaky_relu(tf.matmul(x, w1) + b1)\n",
    "    w2, b2 = parameters[\"w2\"], parameters[\"b2\"]\n",
    "    x_recon = tf.matmul(hidden, w2) + b2\n",
    "    return x_recon, hidden\n",
    "\n",
    "\n",
    "def mse(x, x_recon, name=\"\"):\n",
    "    mse = tf.reduce_mean(tf.square(x_recon-x))\n",
    "    return mse\n",
    "\n",
    "\n",
    "def create_folder(result_folder):\n",
    "    assert(result_folder!=\"\")\n",
    "    path = \"../results/AE/{0}/\".format(result_folder)\n",
    "    if len(glob.glob(path)) == 0:\n",
    "        os.mkdir(path)\n",
    "    return path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_model(data, n_hidden, batch_size=128, \n",
    "                num_epoch=1000, learning_rate=1e-3, result_folder=\"\"):\n",
    "    tf.reset_default_graph()\n",
    "    folder = create_folder(result_folder)\n",
    "    N_IN = data.train.num_features\n",
    "    N_OUT = data.train.num_features\n",
    "    N_HIDDEN = n_hidden\n",
    "    \n",
    "    # train step\n",
    "    (train_batch, train_iter, val_all, val_iter, \n",
    "        train_all, train_iter_all) = data.prep_batch(batch_size=batch_size, \n",
    "                                                     count_by=\"epoch\")\n",
    "    x = train_batch[\"X\"]\n",
    "    x_recon, parameters = build_model(x, N_IN, N_HIDDEN)\n",
    "    train_step = back_prop(x, x_recon, learning_rate)\n",
    "    \n",
    "    # mse\n",
    "    x_train, x_val = train_all[\"X\"], val_all[\"X\"]\n",
    "    x_train_recon, train_latent = feed_forward(x_train, parameters)\n",
    "    x_val_recon, val_latent = feed_forward(x_val, parameters)\n",
    "    train_mse = mse(x_train, x_train_recon, name=\"train\")\n",
    "    val_mse = mse(x_val, x_val_recon, name=\"valiation\")\n",
    "    \n",
    "    # run\n",
    "    sess = tf.Session()\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    train_errors = []\n",
    "    val_errors = []\n",
    "    try:\n",
    "        for epoch in range(num_epoch):\n",
    "            sess.run([train_iter.initializer])\n",
    "            sess.run([train_iter_all.initializer, val_iter.initializer])\n",
    "            t0 = time.time()\n",
    "            try:\n",
    "                while True:\n",
    "                    sess.run(train_step)\n",
    "            except tf.errors.OutOfRangeError:\n",
    "                [train_error, val_error] = sess.run([train_mse, val_mse])             \n",
    "                train_errors.append(train_error)\n",
    "                val_errors.append(val_error)\n",
    "                if epoch % 10 == 0:\n",
    "                    print(\"epoch\", epoch)\n",
    "                    print(\"training mse:\", train_error, \"validation mse\", val_error)\n",
    "                    print(\"epoch time:\", time.time()-t0)\n",
    "    finally:\n",
    "        train_latent = sess.run(train_latent)\n",
    "        val_latent = sess.run(val_latent)\n",
    "        parameter_trained = sess.run(parameters)\n",
    "        parameter_trained[\"total_epoch\"] = epoch\n",
    "        np.save(\"{0}/train_latent.npy\".format(folder), train_latent)\n",
    "        np.save(\"{0}/val_latent.npy\".format(folder), val_latent)\n",
    "        np.save(\"{0}/train_mse.npy\".format(folder), np.array(train_errors))\n",
    "        np.save(\"{0}/val_mse.npy\".format(folder), np.array(val_errors))\n",
    "        with open(\"{0}/parameters.pkl\".format(folder), \"wb\") as f:\n",
    "            pickle.dump(parameter_trained, f)\n",
    "        sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tcga = load_data.read_data_sets(\"../data/mRNA_lognorm_StandardScaled.hdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0\n",
      "training mse: 1.2010224 validation mse 1.2268168\n",
      "epoch time: 1.5647170543670654\n",
      "epoch 10\n",
      "training mse: 0.7047268 validation mse 0.7029766\n",
      "epoch time: 1.040672779083252\n",
      "epoch 20\n",
      "training mse: 0.693651 validation mse 0.693178\n",
      "epoch time: 1.1418237686157227\n",
      "epoch 30\n",
      "training mse: 0.6898328 validation mse 0.69069594\n",
      "epoch time: 1.1333420276641846\n",
      "epoch 40\n",
      "training mse: 0.6861566 validation mse 0.68947136\n",
      "epoch time: 1.1392028331756592\n",
      "epoch 50\n",
      "training mse: 0.6841282 validation mse 0.6890901\n",
      "epoch time: 1.1313567161560059\n",
      "epoch 60\n",
      "training mse: 0.68205935 validation mse 0.6898403\n",
      "epoch time: 1.1300930976867676\n",
      "epoch 70\n",
      "training mse: 0.6802823 validation mse 0.69079053\n",
      "epoch time: 1.147254228591919\n",
      "epoch 80\n",
      "training mse: 0.67901516 validation mse 0.69230014\n",
      "epoch time: 1.1144766807556152\n",
      "epoch 90\n",
      "training mse: 0.67907095 validation mse 0.69431996\n",
      "epoch time: 1.1205041408538818\n",
      "epoch 100\n",
      "training mse: 0.6777765 validation mse 0.69578797\n",
      "epoch time: 1.1108019351959229\n",
      "epoch 110\n",
      "training mse: 0.67792785 validation mse 0.69800127\n",
      "epoch time: 1.1268599033355713\n",
      "epoch 120\n",
      "training mse: 0.67847675 validation mse 0.7006394\n",
      "epoch time: 1.1112327575683594\n",
      "epoch 130\n",
      "training mse: 0.67757356 validation mse 0.7025086\n",
      "epoch time: 1.0826687812805176\n",
      "epoch 140\n",
      "training mse: 0.6767008 validation mse 0.7033929\n",
      "epoch time: 1.1264362335205078\n",
      "epoch 150\n",
      "training mse: 0.67593986 validation mse 0.7031376\n",
      "epoch time: 1.1186692714691162\n",
      "epoch 160\n",
      "training mse: 0.67672014 validation mse 0.7052325\n",
      "epoch time: 1.1132118701934814\n",
      "epoch 170\n",
      "training mse: 0.6764565 validation mse 0.70659834\n",
      "epoch time: 1.1108534336090088\n"
     ]
    }
   ],
   "source": [
    "nodes = [5]\n",
    "for node in nodes:\n",
    "    train_model(tcga, node, num_epoch=2000, result_folder=str(node))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
