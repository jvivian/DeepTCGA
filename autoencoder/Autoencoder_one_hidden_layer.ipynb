{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/molly/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import time\n",
    "import datetime\n",
    "from pprint import pprint as pp\n",
    "import sys\n",
    "import pickle\n",
    "import glob\n",
    "import os\n",
    "\n",
    "sys.path.insert(0, '/home/molly/Desktop/DeepTCGA/')\n",
    "import load_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fc_layer(A_prev, size_in, size_out, name=\"fully-connected\"):\n",
    "    with tf.name_scope(name):\n",
    "        w = tf.Variable(tf.truncated_normal([size_in, size_out], mean=0, stddev=0.1))\n",
    "        b = tf.Variable(tf.constant(0.1, shape=[size_out]))\n",
    "        act = tf.matmul(A_prev, w) + b\n",
    "        return act, w, b\n",
    "\n",
    "    \n",
    "def build_model(x, N_IN, N_HIDDEN):\n",
    "    parameters = {}\n",
    "    z1, w1, b1 = fc_layer(x, N_IN, N_HIDDEN, name=\"fc1\")\n",
    "    parameters.update({\"z1\":z1, \"w1\": w1, \"b1\": b1})\n",
    "    hidden = tf.nn.leaky_relu(z1, name=\"hidden\")\n",
    "    x_recon, w2, b2 = fc_layer(hidden, N_HIDDEN, N_IN, name=\"fc2\")\n",
    "    parameters.update({\"w2\": w2, \"b2\": b2})\n",
    "    return x_recon, parameters\n",
    "\n",
    "\n",
    "def back_prop(x, x_recon, learning_rate):\n",
    "    loss = tf.reduce_mean(tf.square(x_recon - x))\n",
    "    train_step = tf.train.AdamOptimizer(learning_rate).minimize(loss)\n",
    "    return train_step\n",
    "\n",
    "\n",
    "def feed_forward(x, parameters):\n",
    "    w1, b1 = parameters[\"w1\"], parameters[\"b1\"]\n",
    "    hidden = tf.nn.leaky_relu(tf.matmul(x, w1) + b1)\n",
    "    w2, b2 = parameters[\"w2\"], parameters[\"b2\"]\n",
    "    x_recon = tf.matmul(hidden, w2) + b2\n",
    "    return x_recon, hidden\n",
    "\n",
    "\n",
    "def mse(x, x_recon, name=\"\"):\n",
    "    mse = tf.reduce_mean(tf.square(x_recon-x))\n",
    "    return mse\n",
    "\n",
    "\n",
    "def create_folder(result_folder):\n",
    "    assert(result_folder!=\"\")\n",
    "    path = \"../results/AE/{0}/\".format(result_folder)\n",
    "    if len(glob.glob(path)) == 0:\n",
    "        os.mkdir(path)\n",
    "    return path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(data, n_hidden, batch_size=128, \n",
    "                num_epoch=1000, learning_rate=1e-3, result_folder=\"\"):\n",
    "    tf.reset_default_graph()\n",
    "    folder = create_folder(result_folder)\n",
    "    N_IN = data.train.num_features\n",
    "    N_OUT = data.train.num_features\n",
    "    N_HIDDEN = n_hidden\n",
    "    \n",
    "    # train step\n",
    "    (train_batch, train_iter, val_all, val_iter, \n",
    "        train_all, train_iter_all) = data.prep_batch(batch_size=batch_size, \n",
    "                                                     count_by=\"epoch\")\n",
    "    x = train_batch[\"X\"]\n",
    "    x_recon, parameters = build_model(x, N_IN, N_HIDDEN)\n",
    "    train_step = back_prop(x, x_recon, learning_rate)\n",
    "    \n",
    "    # mse\n",
    "    x_train, x_val = train_all[\"X\"], val_all[\"X\"]\n",
    "    x_train_recon, train_latent = feed_forward(x_train, parameters)\n",
    "    x_val_recon, val_latent = feed_forward(x_val, parameters)\n",
    "    train_mse = mse(x_train, x_train_recon, name=\"train\")\n",
    "    val_mse = mse(x_val, x_val_recon, name=\"valiation\")\n",
    "    \n",
    "    # run\n",
    "    sess = tf.Session()\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    train_errors = []\n",
    "    val_errors = []\n",
    "    try:\n",
    "        for epoch in range(num_epoch):\n",
    "            sess.run([train_iter.initializer])\n",
    "            t0 = time.time()\n",
    "            try:\n",
    "                while True:\n",
    "                    sess.run(train_step)\n",
    "            except tf.errors.OutOfRangeError:\n",
    "                sess.run([train_iter_all.initializer, val_iter.initializer])\n",
    "                [train_error, val_error] = sess.run([train_mse, val_mse])\n",
    "                train_errors.append(train_error)\n",
    "                val_errors.append(val_error)\n",
    "                if epoch % 10 == 0:\n",
    "                    print(\"epoch\", epoch)\n",
    "                    print(\"training mse:\", train_error, \"validation mse\", val_error)\n",
    "                    print(\"epoch time:\", time.time()-t0)\n",
    "    finally:\n",
    "        train_latent = sess.run(train_latent)\n",
    "        val_latent = sess.run(val_latent)\n",
    "        parameter_trained = sess.run(parameters)\n",
    "        parameter_trained[\"total_epoch\"] = epoch\n",
    "        np.save(\"{0}/train_latent.npy\".format(folder), train_latent)\n",
    "        np.save(\"{0}/val_latent.npy\".format(folder), val_latent)\n",
    "        with open(\"{0}/parameters.pkl\".format(folder), \"wb\") as f:\n",
    "            pickle.dump(parameter_trained, f)\n",
    "        sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tcga = load_data.read_data_sets(\"../data/mRNA_lognorm_StandardScaled.hdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0\n",
      "training mse: 513.3475 validation mse 619.1425\n",
      "epoch time: 7.027270317077637\n",
      "epoch 10\n",
      "training mse: 88.10996 validation mse 224.1966\n",
      "epoch time: 5.287370920181274\n",
      "epoch 20\n",
      "training mse: 43.066147 validation mse 176.27597\n",
      "epoch time: 5.3054211139678955\n",
      "epoch 30\n",
      "training mse: 40.137268 validation mse 170.9424\n",
      "epoch time: 5.288269996643066\n",
      "epoch 40\n",
      "training mse: 34.099155 validation mse 163.63919\n",
      "epoch time: 5.301032781600952\n",
      "epoch 50\n",
      "training mse: 21.52984 validation mse 146.24998\n",
      "epoch time: 5.261935234069824\n",
      "epoch 60\n",
      "training mse: 18.929178 validation mse 144.52551\n",
      "epoch time: 5.287148714065552\n",
      "epoch 70\n",
      "training mse: 17.108112 validation mse 138.10272\n",
      "epoch time: 5.293067216873169\n",
      "epoch 80\n",
      "training mse: 11.502903 validation mse 126.5247\n",
      "epoch time: 5.3004841804504395\n",
      "epoch 90\n",
      "training mse: 7.6458073 validation mse 114.50571\n",
      "epoch time: 5.287476301193237\n",
      "epoch 100\n",
      "training mse: 6.513771 validation mse 108.278435\n",
      "epoch time: 5.311220169067383\n",
      "epoch 110\n",
      "training mse: 4.6273785 validation mse 100.1544\n",
      "epoch time: 5.297849655151367\n",
      "epoch 120\n",
      "training mse: 2.822222 validation mse 91.744484\n",
      "epoch time: 5.261073589324951\n",
      "epoch 130\n",
      "training mse: 1.591232 validation mse 83.92598\n",
      "epoch time: 5.307016849517822\n",
      "epoch 140\n",
      "training mse: 1.1319985 validation mse 78.58806\n",
      "epoch time: 5.315097093582153\n"
     ]
    }
   ],
   "source": [
    "for node in [8000, 4000, 2000, 1000, 500, 250, 100, 50, 20, 10, 2]:\n",
    "    train_model(tcga, node, num_epoch=2000, result_folder=str(node))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
