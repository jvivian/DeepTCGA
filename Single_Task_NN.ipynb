{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder, LabelBinarizer\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import datetime\n",
    "from tensorflow.python.client import timeline\n",
    "\n",
    "import load_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One hidden layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weight_variable(shape):\n",
    "    initial=tf.truncated_normal(shape, stddev=0.1)\n",
    "    return tf.Variable(initial, name=\"w\")\n",
    "\n",
    "\n",
    "def bias_variable(shape):\n",
    "    initial = tf.constant(0.1, shape=shape)\n",
    "    return tf.Variable(initial, name=\"b\")\n",
    "\n",
    "\n",
    "def fc_layer(input, size_in, size_out, name=\"fc\"):\n",
    "    with tf.name_scope(name):\n",
    "        w = weight_variable([size_in, size_out])\n",
    "        b = bias_variable([size_out])\n",
    "        act = tf.matmul(input, w) + b\n",
    "        tf.summary.histogram(\"weights\", w)\n",
    "        tf.summary.histogram(\"biases\", b)\n",
    "        tf.summary.histogram(\"activations\", act)\n",
    "        return act, w, b\n",
    "\n",
    "\n",
    "def prep_batch(X, y, num_epoch=0, batch_size=0, data_type=\"train\"):\n",
    "    dataset = tf.data.Dataset.from_tensor_slices({\"X\": X, \"y\": y})\n",
    "    if data_type == \"train\":\n",
    "        dataset=dataset.repeat(num_epoch)\n",
    "        dataset=dataset.batch(batch_size)\n",
    "    elif data_type == \"test\":\n",
    "        dataset=dataset.repeat()\n",
    "        dataset=dataset.batch(X.shape[0])        \n",
    "    else:\n",
    "        raise(\"data type \\\"{0}\\\" not supported\".format(data_type))\n",
    "    dataset = dataset.prefetch(2)\n",
    "    iterator = dataset.make_initializable_iterator()\n",
    "    next_batch = iterator.get_next()\n",
    "    x, y_true = next_batch[\"X\"], next_batch[\"y\"]\n",
    "    return x, y_true, iterator\n",
    "\n",
    "\n",
    "def build_model(x, N_IN, N_HIDDEN, N_OUT):\n",
    "    a1, w1, b1 = fc_layer(x, N_IN, N_HIDDEN)\n",
    "    hidden = tf.nn.relu(a1, name=\"hidden\")\n",
    "    y_pred, w2, b2 = fc_layer(hidden, N_HIDDEN, N_OUT, name=\"softmax\")\n",
    "    return y_pred, w1, b1, w2, b2\n",
    "\n",
    "\n",
    "def feed_forward(x, w1, b1, w2, b2):\n",
    "    hidden = tf.nn.relu(tf.matmul(x, w1) + b1)\n",
    "    return tf.matmul(hidden, w2) + b2\n",
    "    \n",
    "\n",
    "def back_prop(y_true, y_pred, learning_rate):\n",
    "    cross_entropy = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(\n",
    "        labels=y_true, logits=y_pred), name=\"cross_entropy_loss\")\n",
    "    tf.summary.scalar(\"cross_entropy_loss\", cross_entropy)\n",
    "    train_step = tf.train.AdamOptimizer(learning_rate).minimize(cross_entropy)\n",
    "    return train_step\n",
    "\n",
    "\n",
    "def accuracy(y_pred, y_true, name=\"\"):\n",
    "    correct_prediction = tf.equal(tf.argmax(y_pred, 1), tf.argmax(y_true, 1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "    summary = tf.summary.scalar(name, accuracy)\n",
    "    return accuracy, summary\n",
    "\n",
    "\n",
    "def train_model(data, label=\"tissue\", batch_size=1000, \n",
    "                num_epoch=1000, learning_rate=1e-3, extra=\"\"):\n",
    "\n",
    "    # set up parameters\n",
    "    tf.reset_default_graph()\n",
    "    LOGDIR = \"/tmp/tcga_{0}/\".format(str(datetime.datetime.today().date()))\n",
    "    N_IN = data.train.X.shape[1]\n",
    "    N_OUT = data.train.y[label].shape[1]\n",
    "    N_HIDDEN = int(np.mean(N_IN + N_OUT)/2)\n",
    "\n",
    "    # set up train step and training accuracy\n",
    "    x, y_true, train_iterator = prep_batch(data.train.X, \n",
    "                                     data.train.y[label],\n",
    "                                     num_epoch=1000, batch_size=1000)\n",
    "    y_pred, w1, b1, w2, b2 = build_model(x, N_IN, N_HIDDEN, N_OUT)\n",
    "    train_step = back_prop(y_true, y_pred, learning_rate)\n",
    "    train_accuracy, train_summ = accuracy(y_true, y_pred, name=\"train_accuracy\")\n",
    "\n",
    "    # set up test accuracy\n",
    "    x_test, y_test_true, test_iterator = prep_batch(\n",
    "        data.test.X, data.test.y[label], data_type=\"test\")\n",
    "    y_test_pred = feed_forward(x_test, w1, b1, w2, b2)\n",
    "    test_accuracy, test_summ = accuracy(y_test_true, y_test_pred, name=\"test_accuracy\")\n",
    "\n",
    "    # prepare session and summary writer\n",
    "    sess = tf.Session()\n",
    "    summ = tf.summary.merge_all()\n",
    "    writer = tf.summary.FileWriter(LOGDIR + \"pca{0}_{1}\".format(extra, label))\n",
    "    writer.add_graph(sess.graph)\n",
    "    \n",
    "    # initializing\n",
    "    t0 = time.time()\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    sess.run([train_iterator.initializer, test_iterator.initializer])\n",
    "    \n",
    "    epoch = 0\n",
    "    train_size = data.train.X.shape[0]\n",
    "    \n",
    "    # training\n",
    "    for i in range(100000000):\n",
    "        try:\n",
    "            sess.run(train_step)\n",
    "            if (i*batch_size) / train_size > epoch:\n",
    "                epoch += 1\n",
    "                [train_accu, train_s, test_accu, test_s] = sess.run(\n",
    "                    [train_accuracy, train_summ, test_accuracy, test_summ])\n",
    "                writer.add_summary(train_s, epoch)\n",
    "                writer.add_summary(test_s, epoch)\n",
    "                if epoch % 100 == 0:\n",
    "                    print(\"epoch\", epoch, \n",
    "                          \"training accuracy\", train_accu, \n",
    "                          \"test_accuracy\", test_accu\n",
    "                         )\n",
    "        except tf.errors.OutOfRangeError:\n",
    "            break\n",
    "    print(\"training time:\", time.time() - t0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6 tissue\n",
      "epoch 100 training accuracy 0.775 test_accuracy 0.821956\n",
      "epoch 200 training accuracy 0.872 test_accuracy 0.883764\n",
      "epoch 300 training accuracy 0.88 test_accuracy 0.893911\n",
      "epoch 400 training accuracy 0.927 test_accuracy 0.892989\n",
      "epoch 500 training accuracy 0.889 test_accuracy 0.895756\n",
      "epoch 600 training accuracy 0.94 test_accuracy 0.899446\n",
      "epoch 700 training accuracy 0.917 test_accuracy 0.899446\n",
      "epoch 800 training accuracy 0.935 test_accuracy 0.901291\n",
      "training time: 12.353695392608643\n",
      "0.6 gender\n",
      "epoch 100 training accuracy 0.696 test_accuracy 0.72417\n",
      "epoch 200 training accuracy 0.739 test_accuracy 0.73155\n",
      "epoch 300 training accuracy 0.692 test_accuracy 0.72417\n",
      "epoch 400 training accuracy 0.728 test_accuracy 0.728782\n",
      "epoch 500 training accuracy 0.694 test_accuracy 0.725092\n",
      "epoch 600 training accuracy 0.726 test_accuracy 0.726015\n",
      "epoch 700 training accuracy 0.733 test_accuracy 0.726937\n",
      "epoch 800 training accuracy 0.726 test_accuracy 0.723247\n",
      "training time: 11.417440414428711\n",
      "0.6 tumor\n",
      "epoch 100 training accuracy 0.912 test_accuracy 0.913284\n",
      "epoch 200 training accuracy 0.956 test_accuracy 0.95941\n",
      "epoch 300 training accuracy 0.961 test_accuracy 0.967712\n",
      "epoch 400 training accuracy 0.961 test_accuracy 0.972325\n",
      "epoch 500 training accuracy 0.966 test_accuracy 0.973247\n",
      "epoch 600 training accuracy 0.961 test_accuracy 0.976015\n",
      "epoch 700 training accuracy 0.976 test_accuracy 0.975092\n",
      "epoch 800 training accuracy 0.961 test_accuracy 0.975092\n",
      "training time: 11.394550323486328\n",
      "0.7 tissue\n",
      "epoch 100 training accuracy 0.91 test_accuracy 0.916052\n",
      "epoch 200 training accuracy 0.915 test_accuracy 0.930812\n",
      "epoch 300 training accuracy 0.938 test_accuracy 0.940037\n",
      "epoch 400 training accuracy 0.956 test_accuracy 0.941882\n",
      "epoch 500 training accuracy 0.944 test_accuracy 0.946494\n",
      "epoch 600 training accuracy 0.953 test_accuracy 0.947417\n",
      "epoch 700 training accuracy 0.948 test_accuracy 0.948339\n",
      "epoch 800 training accuracy 0.953 test_accuracy 0.948339\n",
      "training time: 12.186656951904297\n",
      "0.7 gender\n",
      "epoch 100 training accuracy 0.753 test_accuracy 0.749077\n",
      "epoch 200 training accuracy 0.765 test_accuracy 0.75369\n",
      "epoch 300 training accuracy 0.756 test_accuracy 0.748155\n",
      "epoch 400 training accuracy 0.769 test_accuracy 0.751845\n",
      "epoch 500 training accuracy 0.76 test_accuracy 0.75\n",
      "epoch 600 training accuracy 0.77 test_accuracy 0.751845\n",
      "epoch 700 training accuracy 0.775 test_accuracy 0.750923\n",
      "epoch 800 training accuracy 0.764 test_accuracy 0.747232\n",
      "training time: 11.313851833343506\n",
      "0.7 tumor\n",
      "epoch 100 training accuracy 0.923 test_accuracy 0.940037\n",
      "epoch 200 training accuracy 0.972 test_accuracy 0.97417\n",
      "epoch 300 training accuracy 0.965 test_accuracy 0.975092\n",
      "epoch 400 training accuracy 0.979 test_accuracy 0.975092\n",
      "epoch 500 training accuracy 0.97 test_accuracy 0.975092\n",
      "epoch 600 training accuracy 0.979 test_accuracy 0.975092\n",
      "epoch 700 training accuracy 0.982 test_accuracy 0.975092\n",
      "epoch 800 training accuracy 0.981 test_accuracy 0.97417\n",
      "training time: 11.377281665802002\n",
      "0.8 tissue\n",
      "epoch 100 training accuracy 0.942 test_accuracy 0.952952\n",
      "epoch 200 training accuracy 0.979 test_accuracy 0.95941\n",
      "epoch 300 training accuracy 0.976 test_accuracy 0.960332\n",
      "epoch 400 training accuracy 0.985 test_accuracy 0.960332\n",
      "epoch 500 training accuracy 0.987 test_accuracy 0.958487\n",
      "epoch 600 training accuracy 0.991 test_accuracy 0.958487\n",
      "epoch 700 training accuracy 0.993 test_accuracy 0.956642\n",
      "epoch 800 training accuracy 0.992 test_accuracy 0.95572\n",
      "training time: 13.800131797790527\n",
      "0.8 gender\n",
      "epoch 100 training accuracy 0.998 test_accuracy 0.994465\n",
      "epoch 200 training accuracy 0.998 test_accuracy 0.994465\n",
      "epoch 300 training accuracy 0.999 test_accuracy 0.994465\n",
      "epoch 400 training accuracy 0.998 test_accuracy 0.995387\n",
      "epoch 500 training accuracy 0.998 test_accuracy 0.993542\n",
      "epoch 600 training accuracy 0.999 test_accuracy 0.99262\n",
      "epoch 700 training accuracy 0.999 test_accuracy 0.995387\n",
      "epoch 800 training accuracy 1.0 test_accuracy 0.990775\n",
      "training time: 13.708366394042969\n",
      "0.8 tumor\n",
      "epoch 100 training accuracy 0.977 test_accuracy 0.976937\n",
      "epoch 200 training accuracy 0.989 test_accuracy 0.980627\n",
      "epoch 300 training accuracy 0.982 test_accuracy 0.97786\n",
      "epoch 400 training accuracy 0.987 test_accuracy 0.980627\n",
      "epoch 500 training accuracy 0.984 test_accuracy 0.979705\n",
      "epoch 600 training accuracy 0.99 test_accuracy 0.979705\n",
      "epoch 700 training accuracy 0.997 test_accuracy 0.980627\n",
      "epoch 800 training accuracy 0.998 test_accuracy 0.97786\n",
      "training time: 13.08396053314209\n",
      "0.9 tissue\n",
      "epoch 100 training accuracy 0.981 test_accuracy 0.961255\n",
      "epoch 200 training accuracy 0.998 test_accuracy 0.964022\n",
      "epoch 300 training accuracy 1.0 test_accuracy 0.967712\n",
      "epoch 400 training accuracy 0.999 test_accuracy 0.961255\n",
      "epoch 500 training accuracy 1.0 test_accuracy 0.965867\n",
      "epoch 600 training accuracy 1.0 test_accuracy 0.967712\n",
      "epoch 700 training accuracy 1.0 test_accuracy 0.964945\n",
      "epoch 800 training accuracy 1.0 test_accuracy 0.967712\n",
      "training time: 34.16003751754761\n",
      "0.9 gender\n",
      "epoch 100 training accuracy 0.997 test_accuracy 0.993542\n",
      "epoch 200 training accuracy 0.997 test_accuracy 0.998155\n",
      "epoch 300 training accuracy 1.0 test_accuracy 0.998155\n",
      "epoch 400 training accuracy 0.999 test_accuracy 0.998155\n",
      "epoch 500 training accuracy 1.0 test_accuracy 0.997232\n",
      "epoch 600 training accuracy 0.999 test_accuracy 0.997232\n",
      "epoch 700 training accuracy 1.0 test_accuracy 0.995387\n",
      "epoch 800 training accuracy 0.999 test_accuracy 0.997232\n",
      "training time: 28.724318027496338\n",
      "0.9 tumor\n",
      "epoch 100 training accuracy 0.985 test_accuracy 0.978782\n",
      "epoch 200 training accuracy 0.991 test_accuracy 0.979705\n",
      "epoch 300 training accuracy 0.995 test_accuracy 0.978782\n",
      "epoch 400 training accuracy 0.998 test_accuracy 0.97786\n",
      "epoch 500 training accuracy 0.999 test_accuracy 0.976937\n",
      "epoch 600 training accuracy 0.901 test_accuracy 0.884686\n",
      "epoch 700 training accuracy 0.99 test_accuracy 0.979705\n",
      "epoch 800 training accuracy 0.995 test_accuracy 0.97786\n",
      "training time: 28.775656938552856\n"
     ]
    }
   ],
   "source": [
    "for pca_var in [0.6, 0.7, 0.8, 0.9]:\n",
    "    tcga = load_data.read_data_sets(\"./data/mRNA_PCA_{0}_variance_MinMaxScaled.csv\".format(pca_var))\n",
    "    for label_name in [\"tissue\", \"gender\", \"tumor\"]:\n",
    "        print(pca_var, label_name)\n",
    "        tcga.train.reset_epoch()\n",
    "        train_model(tcga, label=label_name, extra=pca_var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tcga = load_data.read_data_sets(\"./data/mRNA_lognorm_MinMaxScaled.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tissue\n",
      "epoch 100 training accuracy 0.979 test_accuracy 0.946494\n",
      "epoch 200 training accuracy 0.996 test_accuracy 0.958487\n",
      "epoch 300 training accuracy 1.0 test_accuracy 0.958487\n",
      "epoch 400 training accuracy 0.918 test_accuracy 0.910517\n",
      "epoch 500 training accuracy 0.971 test_accuracy 0.950185\n",
      "epoch 600 training accuracy 0.99 test_accuracy 0.954797\n",
      "epoch 700 training accuracy 1.0 test_accuracy 0.95941\n",
      "epoch 800 training accuracy 1.0 test_accuracy 0.95203\n",
      "training time: 1208.1513483524323\n",
      "gender\n",
      "epoch 100 training accuracy 0.987 test_accuracy 0.988007\n",
      "epoch 200 training accuracy 1.0 test_accuracy 0.990775\n",
      "epoch 300 training accuracy 0.974 test_accuracy 0.97048\n",
      "epoch 400 training accuracy 0.997 test_accuracy 0.991697\n",
      "epoch 500 training accuracy 0.995 test_accuracy 0.997232\n",
      "epoch 600 training accuracy 0.998 test_accuracy 0.991697\n",
      "epoch 700 training accuracy 1.0 test_accuracy 0.995387\n",
      "epoch 800 training accuracy 0.999 test_accuracy 0.997232\n",
      "training time: 1133.386573791504\n",
      "tumor\n",
      "epoch 100 training accuracy 0.676 test_accuracy 0.674354\n",
      "epoch 200 training accuracy 0.983 test_accuracy 0.968635\n",
      "epoch 300 training accuracy 0.969 test_accuracy 0.950185\n",
      "epoch 400 training accuracy 0.982 test_accuracy 0.96679\n",
      "epoch 500 training accuracy 0.994 test_accuracy 0.972325\n",
      "epoch 600 training accuracy 0.994 test_accuracy 0.97417\n",
      "epoch 700 training accuracy 0.994 test_accuracy 0.969557\n",
      "epoch 800 training accuracy 0.996 test_accuracy 0.972325\n",
      "training time: 1217.8775403499603\n"
     ]
    }
   ],
   "source": [
    "for label_name in [\"tissue\", \"gender\", \"tumor\"]:\n",
    "    print(label_name)\n",
    "    tcga.train.reset_epoch()\n",
    "    train_model(tcga, label=label_name, extra=\"_all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
