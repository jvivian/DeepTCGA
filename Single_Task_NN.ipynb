{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder, LabelBinarizer\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import datetime\n",
    "\n",
    "import load_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One hidden layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def weight_variable(shape):\n",
    "    initial=tf.truncated_normal(shape, stddev=0.1)\n",
    "    return tf.Variable(initial)\n",
    "\n",
    "\n",
    "def bias_variable(shape):\n",
    "    initial = tf.constant(0.1, shape=shape)\n",
    "    return tf.Variable(initial)\n",
    "\n",
    "\n",
    "def fc_layer(input, size_in, size_out, name=\"fc\"):\n",
    "    with tf.name_scope(name):\n",
    "        w = weight_variable([size_in, size_out])\n",
    "        b = bias_variable([size_out])\n",
    "        act = tf.matmul(input, w) + b\n",
    "        tf.summary.histogram(\"weights\", w)\n",
    "        tf.summary.histogram(\"biases\", b)\n",
    "        tf.summary.histogram(\"activations\", act)\n",
    "        return act\n",
    "    \n",
    "\n",
    "def train_model(data, label=\"tissue\", learning_rate=1e-2):\n",
    "    tf.reset_default_graph()\n",
    "    LOGDIR = \"/tmp/tcga_{0}/\".format(str(datetime.datetime.today().date()))\n",
    "    N_IN = data.train.X.shape[1]\n",
    "    N_OUT = data.train.y[label].shape[1]\n",
    "    N_HIDDEN = int(np.mean(N_IN + N_OUT))\n",
    "    \n",
    "    x = tf.placeholder(tf.float32, [None, N_IN], name=\"x\")\n",
    "    y_true = tf.placeholder(tf.float32, [None, N_OUT], name=\"labels\")\n",
    "    hidden = tf.nn.relu(fc_layer(x, N_IN, N_HIDDEN), name=\"hidden\")\n",
    "    y_pred = fc_layer(hidden, N_HIDDEN, N_OUT, name=\"softmax\")\n",
    "    \n",
    "    with tf.name_scope(\"xent\"):\n",
    "        xent = tf.reduce_mean(\n",
    "            tf.nn.softmax_cross_entropy_with_logits(\n",
    "                labels=y_true, logits=y_pred), name=\"xent\")\n",
    "        tf.summary.scalar(\"xent\", xent)\n",
    "\n",
    "    with tf.name_scope(\"train\"):\n",
    "        train_step = tf.train.AdamOptimizer(learning_rate).minimize(xent)\n",
    "\n",
    "    with tf.name_scope(\"accuracy\"):\n",
    "        correct_prediction = tf.equal(tf.argmax(y_pred, 1), tf.argmax(y_true, 1))\n",
    "        accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "        tf.summary.scalar(\"accuracy\", accuracy)\n",
    "\n",
    "    sess = tf.Session()\n",
    "    summ = tf.summary.merge_all()\n",
    "    writer = tf.summary.FileWriter(LOGDIR + label)\n",
    "    writer.add_graph(sess.graph)\n",
    "    \n",
    "    # training\n",
    "    t0 = time.time()\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "\n",
    "    for i in range(2001):\n",
    "        batch_x, batch_y = data.train.next_batch(100)\n",
    "        sess.run(train_step, feed_dict={x: batch_x, y_true: batch_y[label]})\n",
    "        if i % 5 == 0:\n",
    "            [train_accuracy, s] = sess.run([accuracy, summ],\n",
    "                feed_dict={x: tcga.train.X, y_true: tcga.train.y[label]})\n",
    "    #         [test_accuracy, s] = sess.run([accuracy, summ],\n",
    "    #             feed_dict={x: tcga.test.X, y_true: tcga.test.y[\"tissue\"]})\n",
    "            writer.add_summary(s, i)\n",
    "            if i % 100 == 0:\n",
    "                print(\"step\", i, \"training accuracy\", train_accuracy)\n",
    "    print(\"training time:\", time.time() - t0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tissue\n",
      "step 0 training accuracy 0.134239\n",
      "step 100 training accuracy 0.727262\n",
      "step 200 training accuracy 0.816486\n",
      "step 300 training accuracy 0.867948\n",
      "step 400 training accuracy 0.876583\n",
      "step 500 training accuracy 0.889017\n",
      "step 600 training accuracy 0.887175\n",
      "step 700 training accuracy 0.886599\n",
      "step 800 training accuracy 0.897191\n",
      "step 900 training accuracy 0.899609\n",
      "step 1000 training accuracy 0.903868\n",
      "step 1100 training accuracy 0.885563\n",
      "step 1200 training accuracy 0.90951\n",
      "step 1300 training accuracy 0.906401\n",
      "step 1400 training accuracy 0.908819\n",
      "step 1500 training accuracy 0.910776\n",
      "step 1600 training accuracy 0.901681\n",
      "step 1700 training accuracy 0.910546\n",
      "step 1800 training accuracy 0.902602\n",
      "step 1900 training accuracy 0.906747\n",
      "step 2000 training accuracy 0.902487\n",
      "training time: 14.089812994003296\n",
      "gender\n",
      "step 0 training accuracy 0.488487\n",
      "step 100 training accuracy 0.701934\n",
      "step 200 training accuracy 0.710569\n",
      "step 300 training accuracy 0.72116\n",
      "step 400 training accuracy 0.720815\n",
      "step 500 training accuracy 0.721391\n",
      "step 600 training accuracy 0.701589\n",
      "step 700 training accuracy 0.699401\n",
      "step 800 training accuracy 0.713562\n",
      "step 900 training accuracy 0.717822\n",
      "step 1000 training accuracy 0.712871\n",
      "step 1100 training accuracy 0.721045\n",
      "step 1200 training accuracy 0.723233\n",
      "step 1300 training accuracy 0.723924\n",
      "step 1400 training accuracy 0.716786\n",
      "step 1500 training accuracy 0.719088\n",
      "step 1600 training accuracy 0.724499\n",
      "step 1700 training accuracy 0.718052\n",
      "step 1800 training accuracy 0.723808\n",
      "step 1900 training accuracy 0.717016\n",
      "step 2000 training accuracy 0.725881\n",
      "training time: 8.906046867370605\n",
      "tumor\n",
      "step 0 training accuracy 0.826272\n",
      "step 100 training accuracy 0.893507\n",
      "step 200 training accuracy 0.925167\n",
      "step 300 training accuracy 0.951071\n",
      "step 400 training accuracy 0.958324\n",
      "step 500 training accuracy 0.961662\n",
      "step 600 training accuracy 0.962008\n",
      "step 700 training accuracy 0.960396\n",
      "step 800 training accuracy 0.965922\n",
      "step 900 training accuracy 0.966728\n",
      "step 1000 training accuracy 0.967419\n",
      "step 1100 training accuracy 0.966152\n",
      "step 1200 training accuracy 0.967649\n",
      "step 1300 training accuracy 0.9688\n",
      "step 1400 training accuracy 0.961087\n",
      "step 1500 training accuracy 0.967649\n",
      "step 1600 training accuracy 0.967764\n",
      "step 1700 training accuracy 0.969146\n",
      "step 1800 training accuracy 0.969837\n",
      "step 1900 training accuracy 0.966037\n",
      "step 2000 training accuracy 0.969952\n",
      "training time: 9.273644924163818\n"
     ]
    }
   ],
   "source": [
    "tcga = load_data.read_data_sets(\"./data/mRNA_PCA_0.6_variance_MinMaxScaled.csv\")\n",
    "for label_name in [\"tissue\", \"gender\", \"tumor\"]:\n",
    "    print(label_name)\n",
    "    tcga.train.reset_epoch()\n",
    "    train_model(tcga, label=label_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
